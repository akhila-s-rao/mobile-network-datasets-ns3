{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d2e3e665-f8c9-4dc0-8ad9-94ec774bbc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dff9e1d9-f635-4ec2-abe5-f4e8c87e9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8aa75b9b-2ebf-400d-9897-81fae82ec05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redirect all print statements to file instead of console\n",
    "\n",
    "#file_path = 'sanity_check_logs_all_runs.txt'\n",
    "#sys.stdout = open(file_path, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "32a0da73-cb4b-4b4e-8b24-5570a7016de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the file names and categories \n",
    "\n",
    "# All the log files from the ns-3 inbuilt RAN logs enabled by EnableTraces() \n",
    "# I have removed the Interference file because it was Goddamn huge and I did not plan on using it anyway\n",
    "ran_files = ['DlTxPhyStats.txt', 'UlRxPhyStats.txt', \n",
    "             'UlSinrStats.txt', 'UlPdcpStats.txt', 'DlRsrpSinrStats.txt', \n",
    "             'UlRlcStats.txt', 'UlMacStats.txt', 'UlTxPhyStats.txt', \n",
    "             'DlPdcpStats.txt', 'DlRlcStats.txt', 'DlRxPhyStats.txt', \n",
    "             'DlMacStats.txt']\n",
    "\n",
    "# All application related files and mobility trace that could exist\n",
    "app_files = ['vrBurst_trace.txt', 'vrFragment_trace.txt', # VR\n",
    "             'dashClient_trace.txt', 'mpegPlayer_trace.txt', # video streaming\n",
    "             'httpServerDelay_trace.txt', 'httpClientDelay_trace.txt', 'httpClientRtt_trace.txt', # web browsing\n",
    "             'dlThroughput_trace.txt', 'ulThroughput_trace.txt', # throughput measurement\n",
    "             'delay_trace.txt', 'rtt_trace.txt', # delay measurement\n",
    "             'flow_trace.txt'] # UDP flow \n",
    "\n",
    "# Other files that have connectivity and location info\n",
    "other_files = ['gnb_locations.txt', 'handover_trace.txt', 'mobility_trace.txt']\n",
    "\n",
    "# These are files that keep track of the bytes flying through the different layer.\n",
    "# I am interested in this specific group to make sure that the bytes flow through \n",
    "# the layers is roughly the same after accounting for headers, and to also make sure\n",
    "# that what is expected for UL and DL are satisfied. \n",
    "files_with_bytes = ['DlTxPhyStats.txt', 'DlRxPhyStats.txt',\n",
    "                    'UlTxPhyStats.txt', 'UlRxPhyStats.txt',\n",
    "                    'DlMacStats.txt', 'UlMacStats.txt',\n",
    "                    'DlRlcStats.txt', 'UlRlcStats.txt',  \n",
    "                    'DlPdcpStats.txt', 'UlPdcpStats.txt']\n",
    "\n",
    "# Some internally generated files have a trailing tab at the end of each row, \n",
    "# but not at the end of the first header row\n",
    "# This causes the read_csv function to read the data weirdly. \n",
    "# So these files have been grouped to fix that\n",
    "files_with_trailing_tab=['DlRlcStats.txt', 'UlRlcStats.txt', \n",
    "                         'DlPdcpStats.txt', 'UlPdcpStats.txt']\n",
    "\n",
    "# The timestamp unit in different RAN log files is different, even though they are all generated by the same \n",
    "# internal ns-3 logging system (eye roll)\n",
    "file_name_to_tstamp_unit = {'DlTxPhyStats.txt':'ms', 'UlRxPhyStats.txt':'ms', \n",
    "                            'UlSinrStats.txt':'s', 'UlPdcpStats.txt':'s', 'DlRsrpSinrStats.txt':'s', \n",
    "                            'UlRlcStats.txt':'s', 'UlMacStats.txt':'s', 'UlTxPhyStats.txt':'ms', \n",
    "                            'DlPdcpStats.txt':'s', 'DlRlcStats.txt':'s', 'DlRxPhyStats.txt':'ms', \n",
    "                            'DlMacStats.txt':'s'}\n",
    "\n",
    "# The internal log files do not follow a consistent naming convention for some metrics\n",
    "# and hence I need to isolate them and fix it\n",
    "files_that_use_upper_case_cellid=['UlPdcpStats.txt', 'UlRlcStats.txt', 'DlPdcpStats.txt', 'DlRlcStats.txt']\n",
    "\n",
    "# columns that are not features and hence can be removed if counting number of features\n",
    "nonfeature_columns = ['tstamp_us', 'ueId', 'IMSI', 'cellId', 'dir', 'pktUid']\n",
    "\n",
    "# this is not in files so no need to remove\n",
    "not_to_be_used_now=['UlInterferenceStats.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fd5f59f1-2aef-4cd7-aef9-2a8fe85c5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which files are we actually interested in looking at \n",
    "\n",
    "# this has all files except interference\n",
    "files = ran_files + app_files + other_files \n",
    "\n",
    "# This is a subset of log files that we would like to parse and plot at the moment depending on what is in the data \n",
    "temp_subset = ['rtt_trace.txt', 'delay_trace.txt', 'ulThroughput_trace.txt']\n",
    "#temp_subset = ['httpServerDelay_trace.txt'] \n",
    "#               'httpClientDelay_trace.txt', 'httpClientRtt_trace.txt']\n",
    "#               'delay_trace.txt', 'rtt_trace.txt',\n",
    "#               'dashClient_trace.txt', 'mpegPlayer_trace.txt']\n",
    "#               'flow_trace.txt', 'mobility_trace.txt']\n",
    "#               'DlTxPhyStats.txt', 'UlRxPhyStats.txt', # at enb \n",
    "#               'UlSinrStats.txt', 'UlPdcpStats.txt', 'DlRsrpSinrStats.txt', \n",
    "#               'UlRlcStats.txt', 'UlMacStats.txt', 'UlTxPhyStats.txt', \n",
    "#               'DlPdcpStats.txt', 'DlRlcStats.txt', 'DlRxPhyStats.txt', \n",
    "#               'DlMacStats.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5bdf0bf6-292f-4f82-ad01-00f8fe889f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================\n",
    "# What to plot\n",
    "#=================================== \n",
    "timeseries_plots = False\n",
    "mobility_plots = False\n",
    "histogram_plots = True\n",
    "distance_plots = False\n",
    "\n",
    "time_wind_str = '500ms'\n",
    "time_wind_val = 500\n",
    "#===================================\n",
    "# Data source\n",
    "#=================================== \n",
    "#data_dir = '../lte_3macro_30Ue_delay_rtt/'\n",
    "#data_dir = '../lte_21macro_210Ue_delay_rtt/'\n",
    "#data_dir = '../lte_21macro_21Ue_delay_rtt_1Ue_dlThput/'\n",
    "data_dir = '../lte_21macro_21Ue_delay_rtt_1Ue_ulThput/'\n",
    "\n",
    "# Specify here topology details from the dataset we are using \n",
    "# This can be infered from the files, but this is easier \n",
    "total_num_cells=3\n",
    "total_num_ues=30\n",
    "num_runs = 10\n",
    "sim_time = 1000 # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8b5242bc-835c-4225-a5bf-da0b015b08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================\n",
    "# Sanity checks that this script runs \n",
    "#=======================================\n",
    "\n",
    "# Runtime: Did all logs for all runs generate data for the entire simulation duration (prints)\n",
    "\n",
    "# IDs: ue_id / cell_id presence in logs. Does each log have representation from\n",
    "#      all the UEs and cells that should be present (prints)\n",
    "\n",
    "# Delay histograms: Are there any ridiculously large delays in the data that cannot be explained. \n",
    "#                   (delay, rtt trace histograms combined for all UEs)\n",
    "\n",
    "# Thput histograms: Understand the throuphput variability caused by only signal variations and not user contention  \n",
    "#                   ul/dl histograms combined for all UEs  \n",
    "\n",
    "# Byte Matrix: Are the number of bits going over the network at the different layers similar ? : (byte matrix)\n",
    "#              Is the traffic UL and DL as expected based on the traffic being sent. \n",
    "#              Is it symetric when there is no one way traffric ? : (byte matrix)\n",
    "\n",
    "# Mobility plot: Plot the movement of the UEs and make sure they make sense \n",
    "\n",
    "# Delay probe delivery rate: Combined for all UEs to check how droppy this network is\n",
    "\n",
    "# Plot per UE cell ID: \n",
    "# Print number of handovers per unti time\n",
    "\n",
    "# Plot distance to BS versus delay/rtt: combined for all UEs\n",
    "# Plot distance to BS versus ul/dl throughput: combined for all UEs\n",
    "# Plot distance to BS versus signal strength: combined for all UEs (rsrp, ul sinr, dl sinr)\n",
    "#                                             NOTE: power control is being used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b9887b27-0b91-4640-a132-eaa890cf2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================\n",
    "# Organising UEs into groups \n",
    "#=======================================\n",
    "\n",
    "# Slow moving UEs group \n",
    "# Fast moving UEs group \n",
    "# Web browsing UEs group \n",
    "# Video streaming UEs group \n",
    "# VR UEs group \n",
    "# No traffic apps UEs group \n",
    "# Thput measurement UE \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Separate out the IDs of the UEs that have a specific set of apps running on them  \n",
    "#ueIds = np.arange(0,total_num_ues)\n",
    "# UEs with only delay measurements and no background traffic:\n",
    "#isIncluded=np.array( [((x % 5) == 0) for x in range(0,total_num_ues)], dtype=bool)\n",
    "#trafficClass1_ueIds=ueIds[isIncluded]\n",
    "# UEs with video streams:\n",
    "#isIncluded=np.array( [ ( ((x % 5) != 0) and (x%2 ==0) ) for x in range(0,total_num_ues)], dtype=bool)\n",
    "#trafficClass2_ueIds=ueIds[isIncluded]\n",
    "# UEs with web browsing:\n",
    "#isIncluded=np.array( [ ( ((x % 5) != 0) and (x%2 !=0) ) for x in range(0,total_num_ues)], dtype=bool)\n",
    "#trafficClass3_ueIds=ueIds[isIncluded]\n",
    "\n",
    "\n",
    "#print('expected num UEs with video streams:', len(trafficClass2_ueIds))\n",
    "#print('expected num UEs with video streams:', len(trafficClass2_ueIds))\n",
    "#print('expected num UEs with web browsing:', len(trafficClass3_ueIds))\n",
    "#print('expected num UEs with UDP background traffic:', (len(trafficClass2_ueIds) + len(trafficClass3_ueIds)))\n",
    "#print('expected num UEs with delay measurements:', len(ueIds))\n",
    "#print('expected num UEs with only delay measurements and no background traffic:', len(trafficClass1_ueIds))\n",
    "\n",
    "#print(trafficClass3_ueIds)\n",
    "#!!!!!! But I do not know what the IMSI of these ueIds are \n",
    "#Maybe I should create these groups in ns3 code using IMSI instead of ueId "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b21cda5d-6aac-4dbc-a6b6-a1c21ddae300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================\n",
    "# Initilizing empty lists \n",
    "#=======================================\n",
    "\n",
    "# To measure delay probe delivery rate \n",
    "ul_delay_probe_delivery_rate = 0\n",
    "dl_delay_probe_delivery_rate = 0\n",
    "rtt_probe_delivery_rate = 0\n",
    "\n",
    "# Baselines for empty networks\n",
    "# Aggregate over UEs and runs for histogram plots\n",
    "ul_delays = np.empty(0)\n",
    "dl_delays = np.empty(0)\n",
    "rtt_delays = np.empty(0)\n",
    "ul_thput = np.empty(0)\n",
    "dl_thput = np.empty(0)\n",
    "\n",
    "# Baselines for empty networks\n",
    "# distance to BS versus metrics \n",
    "ul_delay_vs_dist = np.empty(0)\n",
    "dl_delay_vs_dist = np.empty(0)\n",
    "rtt_delay_vs_dist = np.empty(0)\n",
    "\n",
    "ul_thput_vs_dist = np.empty(0)\n",
    "dl_thput_vs_dist = np.empty(0)\n",
    "\n",
    "ul_sinr_vs_dist = np.empty(0)\n",
    "dl_sinr_vs_dist = np.empty(0)\n",
    "dl_rsrp_vs_dist = np.empty(0)\n",
    "\n",
    "# app specific observations for plotting\n",
    "# aggregated over all UEs running this app to plot histograms \n",
    "page_load_time = np.empty(0) # page load time over all webpages viewed \n",
    "segment_bitrate = np.empty(0) # bitrate of segment requested over all videos watched\n",
    "vr_burst_time = np.empty(0) # time to receive a full burst in VR \n",
    "\n",
    "# constant multipliers\n",
    "M = (10**6)\n",
    "K = (10**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7fc63b89-6395-498e-be55-08c81c859209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "../lte_21macro_21Ue_delay_rtt_1Ue_ulThput/run3\n",
      "============================================================\n",
      "--------------------------------------------\n",
      "rtt_trace.txt\n",
      "time to read file:  0.0035414695739746094\n",
      "log time (start, end): ( 5.18999e-07 ,  1.831999e-06 )\n",
      "log runtime: 1.313  seconds\n",
      "Sum of RTT probes for all UEs:  130\n",
      "--------------------------------------------\n",
      "delay_trace.txt\n",
      "time to read file:  0.002503633499145508\n",
      "log time (start, end): ( 5.33999e-07 ,  1.846999e-06 )\n",
      "log runtime: 1.3130000000000002  seconds\n",
      "Sum of Delay probes for all UEs: UL:  131  DL:  243\n",
      "--------------------------------------------\n",
      "ulThroughput_trace.txt\n",
      "time to read file:  0.003993034362792969\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [197]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelay\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39mK\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#=======================================\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Print log file info  \u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m#=======================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m## Total runtime of log\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog time (start, end): (\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtstamp_us\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m ,df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtstamp_us\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog runtime:\u001b[39m\u001b[38;5;124m'\u001b[39m, (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtstamp_us\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtstamp_us\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m#=======================================\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Aggregate metrics over runs  \u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m#=======================================\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m## Gather the number of bytes sent from/to all UEs in each layer and direction to compare\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/data-process/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/data-process/lib/python3.10/site-packages/pandas/core/indexing.py:1520\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1520\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/data-process/lib/python3.10/site-packages/pandas/core/indexing.py:1452\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1450\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "#=======================================\n",
    "# Iterate over runs and files \n",
    "#=======================================\n",
    "\n",
    "\n",
    "#=================================================================\n",
    "#for run in os.listdir(data_dir):\n",
    "for run in glob.glob(data_dir+'run*'):\n",
    "#for run in ['run1']:\n",
    "#=================================================================\n",
    "\n",
    "    print('============================================================')\n",
    "    print (run)\n",
    "    print('============================================================')\n",
    "    # To store and compare the number of bytes sent and received in different RAN layers \n",
    "    bytes_matrix = np.zeros((4, 4), dtype=int)\n",
    "    \n",
    "    ## Iterate over log files in each run\n",
    "    ## Use temp_subset instead of files if I only want to investigate a subset for now\n",
    "    ax = [None] * total_num_ues\n",
    "    \n",
    "#=================================================================\n",
    "    for file in temp_subset:\n",
    "#=================================================================\n",
    "        print('--------------------------------------------')\n",
    "        print(file)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #=======================================\n",
    "        # Preprocess logs \n",
    "        #=======================================\n",
    "        \n",
    "        ## Read file while fixing the tab issue\n",
    "        if file in files_with_trailing_tab:\n",
    "            df = pd.read_csv(data_dir+run+'/'+file, sep='\\t', usecols=range(0,18))\n",
    "        else:\n",
    "            df = pd.read_csv(data_dir+run+'/'+file, sep='\\t')\n",
    "        \n",
    "        print('time to read file: ', (time.time() - start_time))\n",
    "        \n",
    "        ## Do some file specific preprocessing\n",
    "        ## Make uniform the timestamp units\n",
    "        if '% time' in df.columns:\n",
    "            df.rename(columns = {'% time':'tstamp_us'}, inplace = True)\n",
    "            if file_name_to_tstamp_unit[file] == 'ms':\n",
    "                df['tstamp_us'] = df['tstamp_us']*(10**3)\n",
    "            elif file_name_to_tstamp_unit[file] == 's':\n",
    "                df['tstamp_us'] = df['tstamp_us']*(10**6)\n",
    "        ## Make uniform the timestamp units        \n",
    "        if '% start' in df.columns:\n",
    "            ## TO DO: check if this is actually micro seconds. I think it is seconds   \n",
    "            df.rename(columns = {'% start':'tstamp_us'}, inplace = True)\n",
    "            df.rename(columns = {'end':'end_timeslot_us'}, inplace = True)\n",
    "            df['tstamp_us'] = df['tstamp_us']*(10**6)\n",
    "            df['end_timeslot_us'] = df['end_timeslot_us']*(10**6)\n",
    "        ## Some internally generated logs use the naming 'CellId' replace that with 'cellId'\n",
    "        if 'CellId' in df.columns:\n",
    "            df.rename(columns = {'CellId':'cellId'}, inplace = True)\n",
    "        \n",
    "        ## Just for plotting change the timestamp_us to seconds and delay values to milli seconds \n",
    "        ## since I am mostly plotting directly from pandas and don't know how to add a multiplicative factor to a column \n",
    "        df['tstamp_us'] = df['tstamp_us']/(10**6)\n",
    "        # converting all delay values to ms instead of us\n",
    "        if 'delay' in df.columns:\n",
    "            df['delay'] = df['delay']/K\n",
    "        \n",
    "        \n",
    "        #=======================================\n",
    "        # Print log file info  \n",
    "        #=======================================\n",
    "\n",
    "        ## Display info about the UEs who have made entries in this file to make sure that all the UEs who should be here are here. \n",
    "        #print('ueIds: min:', min(df['IMSI'].value_counts().index), 'max:', max(df['IMSI'].value_counts().index),\n",
    "        #     'count:', len(df['IMSI'].value_counts().index))\n",
    "        \n",
    "        ## Display info about the Cells who have made entries in this file\n",
    "        #print('cellIds: min:', min(df['cellId'].value_counts().index), 'max:', max(df['cellId'].value_counts().index),\n",
    "        #     'count:', len(df['cellId'].value_counts().index))\n",
    "        \n",
    "        ## Total runtime of log\n",
    "        print('log time (start, end): (', df['tstamp_us'].iloc[0]/(10**6), ', ' ,df['tstamp_us'].iloc[-1]/(10**6), ')')\n",
    "        print('log runtime:', (df['tstamp_us'].iloc[-1] - df['tstamp_us'].iloc[0]), ' seconds')\n",
    "        \n",
    "        \n",
    "        #=======================================\n",
    "        # Aggregate metrics over runs  \n",
    "        #=======================================\n",
    "        \n",
    "        ## Gather the number of bytes sent from/to all UEs in each layer and direction to compare\n",
    "        if file == 'DlTxPhyStats.txt':\n",
    "            bytes_matrix[0,0] = df['size'].sum()/M\n",
    "        elif file == 'DlRxPhyStats.txt':\n",
    "            bytes_matrix[2,0] = df['size'].sum()/M\n",
    "        elif file == 'UlTxPhyStats.txt':\n",
    "            bytes_matrix[1,0] = df['size'].sum()/M\n",
    "        elif file == 'UlRxPhyStats.txt':\n",
    "            bytes_matrix[3,0] = df['size'].sum()/M\n",
    "        elif file == 'DlMacStats.txt':\n",
    "            bytes_matrix[0,1] = (df['sizeTb1'].sum() + df['sizeTb2'].sum())/M\n",
    "        elif file == 'UlMacStats.txt':\n",
    "            bytes_matrix[1,1] = df['size'].sum()/M\n",
    "        elif file == 'DlRlcStats.txt':\n",
    "            bytes_matrix[0,2] = df['TxBytes'].sum()/M\n",
    "            bytes_matrix[2,2] = df['RxBytes'].sum()/M\n",
    "        elif file == 'UlRlcStats.txt':\n",
    "            bytes_matrix[1,2] = df['TxBytes'].sum()/M\n",
    "            bytes_matrix[3,2] = df['RxBytes'].sum()/M\n",
    "        elif file == 'DlPdcpStats.txt':\n",
    "            bytes_matrix[0,3] = df['TxBytes'].sum()/M\n",
    "            bytes_matrix[2,3] = df['RxBytes'].sum()/M\n",
    "        elif file == 'UlPdcpStats.txt':\n",
    "            bytes_matrix[1,3] = df['TxBytes'].sum()/M\n",
    "            bytes_matrix[3,3] = df['RxBytes'].sum()/M\n",
    "    \n",
    "        ## Group by UE\n",
    "        #if file == 'dashClient_trace.txt':\n",
    "            #print(    df.groupby(by=['IMSI'])['segmentId'].size()    )   # count   \n",
    "            #print(    (df.groupby(by=['IMSI'])['segmentId'].max() - df.groupby(by=['IMSI'])['segmentId'].min() + 1)   )   # expected count\n",
    "        # this means there are no in between missing logs, they are just not going beyond a certain point and stopping \n",
    "        # at different times for each UE and at different times in each run. \n",
    "\n",
    "        if file == 'delay_trace.txt':\n",
    "            # separate UL and DL \n",
    "            ul_probes = df.groupby(by=['dir']).get_group('UL').groupby(by=['IMSI']).size()\n",
    "            dl_probes = df.groupby(by=['dir']).get_group('DL').groupby(by=['IMSI']).size()\n",
    "            # group by UE\n",
    "            #print('UL # delay probes per UE: ', ul_probes)\n",
    "            #print('DL # delay probes per UE: ', dl_probes)\n",
    "            print('Sum of Delay probes for all UEs: UL: ', ul_probes.sum(), ' DL: ', dl_probes.sum())\n",
    "            ul_delay_probe_delivery_rate = ul_delay_probe_delivery_rate + ul_probes.sum()\n",
    "            dl_delay_probe_delivery_rate = dl_delay_probe_delivery_rate + dl_probes.sum()\n",
    "            # for histogram\n",
    "            ul_delays = np.append(ul_delays, df.groupby(by=['dir']).get_group('UL')['delay'])\n",
    "            dl_delays = np.append(dl_delays, df.groupby(by=['dir']).get_group('DL')['delay'])\n",
    "            \n",
    "        if file == 'rtt_trace.txt':\n",
    "            rtt_probes = df.groupby(by=['IMSI']).size()\n",
    "            # group by UE\n",
    "            #print('# RTT probes per UE: ', rtt_probes)\n",
    "            print('Sum of RTT probes for all UEs: ', rtt_probes.sum())\n",
    "            rtt_probe_delivery_rate = rtt_probe_delivery_rate + rtt_probes.sum()\n",
    "            # for histogram\n",
    "            rtt_delays = np.append(rtt_delays, df['delay'])\n",
    "        \n",
    "        if file == 'ulThroughput_trace.txt':\n",
    "            # Need to create a datetime index to use the resample function \n",
    "            # assuming only one node is sending thput measurement pkts \n",
    "            df['tstamp_us'] = pd.to_datetime(df['tstamp_us'])\n",
    "            df.set_index('tstamp_us', inplace=False)\n",
    "            ul_thput = np.append(ul_thput, df['pktSize'].resample(time_wind_str).sum()/time_wind_val)\n",
    "            \n",
    "        if file == 'dlThroughput_trace.txt':\n",
    "            # Need to create a datetime index to use the resample function \n",
    "            # assuming only one node is sending thput measurement pkts \n",
    "            df['tstamp_us'] = pd.to_datetime(df['tstamp_us'])\n",
    "            df.set_index('tstamp_us', inplace=False)\n",
    "            dl_thput = np.append(dl_thput, df['pktSize'].resample(time_wind_str).sum()/time_wind_val)    \n",
    "        \n",
    "        if file == 'flow_trace.txt':\n",
    "            # separate UL and DL \n",
    "            ul_brate = df.groupby(by=['dir']).get_group('UL').groupby(by=['IMSI'])['pktSize'].sum()/(10**6) # MB\n",
    "            ul_brate = ul_brate*8/(df['tstamp_us'].iloc[-1] - df['tstamp_us'].iloc[0]) \n",
    "            dl_brate = df.groupby(by=['dir']).get_group('DL').groupby(by=['IMSI'])['pktSize'].sum()/(10**6) # MB\n",
    "            dl_brate = dl_brate*8/(df['tstamp_us'].iloc[-1] - df['tstamp_us'].iloc[0]) \n",
    "            # group by UE\n",
    "            print('UL brate Mbps per UE: ', ul_brate)\n",
    "            print('DL brate Mbps per UE: ', dl_brate)\n",
    "            #print('UL Giga Bytes sent by each UE over the duration of the simulation: ', ul_bytes_sent)\n",
    "            #print('DL Giga Bytes sent by each UE over the duration of the simulation: ', dl_bytes_sent)\n",
    "            \n",
    "        #=======================================\n",
    "        # Plot timeseries   \n",
    "        #=======================================\n",
    "        \n",
    "        if timeseries_plots:       \n",
    "                       \n",
    "            ## RAN plots\n",
    "            if file == 'UlSinrStats.txt':\n",
    "                ## Group by UE \n",
    "                ## Time series plot\n",
    "                df_grouped = df.groupby(by=['IMSI'])\n",
    "                for name, df_ue in df_grouped:\n",
    "                    ## temp\n",
    "                    #if (name == 1) or (name == 3):\n",
    "                    df_ue['sinrLinear'] = 10*np.log10(df_ue['sinrLinear'])\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='sinrLinear', sharey=True,\n",
    "                                               ylabel='UL SINR (dB)', xlabel='Time stamp (seconds)', title=name,\n",
    "                                               figsize=(20,3), color='cyan', kind='scatter', ax=ax[name-1])\n",
    "                \n",
    "            \n",
    "            if file == 'DlRsrpSinrStats.txt':\n",
    "                ## Group by UE \n",
    "                ## Time series plot\n",
    "                df_grouped = df.groupby(by=['IMSI'])\n",
    "                for name, df_ue in df_grouped:\n",
    "                    ## temp\n",
    "                    #if (name == 1) or (name == 3):\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='cellId', sharey=True,\n",
    "                                               ylabel='CellId', xlabel='Time stamp (seconds)', title=name,\n",
    "                                               figsize=(20,3), color='red', kind='scatter', ax=ax[name-1])\n",
    "                    #df_ue.plot(x='tstamp_us', y='rsrp', subplots=True,\n",
    "                    #                           ylabel='RSRP', xlabel='Time stamp (seconds)', title=name,\n",
    "                    #                           figsize=(20,3), color='pink', kind='scatter')\n",
    "                \n",
    "            if file == 'DlMacStats.txt':\n",
    "               ## Group by UE \n",
    "                ## Time series plot\n",
    "                df_grouped = df.groupby(by=['IMSI'])\n",
    "                for name, df_ue in df_grouped:\n",
    "                    ## temp\n",
    "                    #if (name == 1) or (name == 3):\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='mcsTb1', \n",
    "                                               ylabel='MCS', xlabel='Time stamp (seconds)', title=name,\n",
    "                                               figsize=(20,3), color='blue', kind='scatter', ax=ax[name-1])\n",
    "            if file == 'UlMacStats.txt':\n",
    "                ## Group by UE \n",
    "                    ## Time series plot\n",
    "                    df_grouped = df.groupby(by=['IMSI'])\n",
    "                    for name, df_ue in df_grouped:\n",
    "                        ## temp\n",
    "                        #if (name == 1) or (name == 3):\n",
    "                        plt.figure(name)\n",
    "                        ax[name-1] = df_ue.plot(x='tstamp_us', y='mcs', \n",
    "                                                   ylabel='MCS', xlabel='Time stamp (seconds)', title=name,\n",
    "                                                   figsize=(20,3), color='green', kind='scatter', ax=ax[name-1])\n",
    "            \n",
    "            \n",
    "            ## OWD plots \n",
    "            if file == 'delay_trace.txt': \n",
    "                ## Group by UE per direction \n",
    "                df_ul = df.groupby(by=['dir']).get_group('UL').groupby(by=['IMSI']).agg(['count'])\n",
    "                df_dl = df.groupby(by=['dir']).get_group('DL').groupby(by=['IMSI']).agg(['count'])\n",
    "                ## Time series plot\n",
    "                for name, df_ue in df_ul:\n",
    "                    #if (name == 1) or (name == 3):\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='delay', xlabel='Time stamp (seconds)', ylabel='UL delay (milli s)', title=name, \n",
    "                                             figsize=(20,3), color='magenta', kind='scatter', ax=ax[name-1])\n",
    "                    \n",
    "                for name, df_ue in df_dl:\n",
    "                    #if (name == 1) or (name == 3):\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='delay', xlabel='Time stamp (seconds)', ylabel='DL delay (milli s)', title=name, \n",
    "                                             figsize=(20,3), color='gold', kind='scatter', ax=ax[name-1])\n",
    "\n",
    "            ## RTT plots\n",
    "            elif file == 'rtt_trace.txt':\n",
    "                ## Group by UE \n",
    "                ## Time series plot\n",
    "                df_grouped = df.groupby(by=['IMSI'])\n",
    "                for name, df_ue in df_grouped:\n",
    "                    ## temp\n",
    "                    #if (name == 1) or (name == 3):\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='delay', \n",
    "                                               ylabel='RTT delay (milli s)', xlabel='Time stamp (seconds)', title=name,\n",
    "                                               figsize=(20,3), color='green', kind='scatter', ax=ax[name-1])\n",
    "\n",
    "            ## Browsing: Time between object request and object download (confirm this from the ns3 model) \n",
    "            elif file == 'httpClientRtt_trace.txt':\n",
    "                ## Group by UE\n",
    "                ## Time series plot\n",
    "                df_grouped = df.groupby(by=['IMSI'])\n",
    "                for name, df_ue in df_grouped:\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='delay', \n",
    "                                               ylabel='http object RTT (milli s)', xlabel='Time stamp (seconds)', title=name,\n",
    "                                               figsize=(20,3), color='magenta', kind='scatter', ax=ax[name-1])\n",
    "\n",
    "            ## Browsing: Time to download object (confirm this from the ns3 model)\n",
    "            elif file == 'httpClientDelay_trace.txt':\n",
    "                df_grouped = df.groupby(by=['IMSI'])\n",
    "                for name, df_ue in df_grouped:\n",
    "                    plt.figure(name)\n",
    "                    ax[name-1] = df_ue.plot(x='tstamp_us', y='delay', \n",
    "                                               ylabel='http object delay (milli s)', xlabel='Time stamp (seconds)', title=name,\n",
    "                                               figsize=(20,3), color='gold', kind='scatter', ax=ax[name-1])\n",
    "        \n",
    "        # end of timeseries_plots\n",
    "    \n",
    "    ## Print per run byte matrix in MB\n",
    "    # print ('Byte Matrix in MB')\n",
    "    #print('  X  phy mac rlc pdcp\\n' +\n",
    "    #      'dlTx  x   x   x   x\\n' +\n",
    "    #      'ulTx  x   x   x   x\\n' +\n",
    "    #      'dlRx  x   x   x   x\\n' +\n",
    "    #      'ulRx  x   x   x   x')\n",
    "    #print(bytes_matrix)\n",
    "\n",
    "# end of for over runs\n",
    "print('============================================================')\n",
    "\n",
    "# print delivery rates over all runs     \n",
    "ul_delay_probe_delivery_rate = ul_delay_probe_delivery_rate/(10*sim_time*total_num_ues*num_runs)  \n",
    "dl_delay_probe_delivery_rate = dl_delay_probe_delivery_rate/(10*sim_time*total_num_ues*num_runs)\n",
    "rtt_probe_delivery_rate = rtt_probe_delivery_rate/(10*sim_time*total_num_ues*num_runs)\n",
    "print(\"UL delay probe delivery rate\", ul_delay_probe_delivery_rate)\n",
    "print(\"DL delay probe delivery rate\", dl_delay_probe_delivery_rate)\n",
    "print(\"RTT probe delivery rate\", rtt_probe_delivery_rate)\n",
    "print('--------------------------------------------')\n",
    "print(\"Summary stats: ul_delays\")\n",
    "print(pd.Series(ul_delays).describe())\n",
    "print(\"Summary stats: dl_delays\")\n",
    "print(pd.Series(ul_delays).describe())\n",
    "print(\"Summary stats: rtt_delays\")\n",
    "print(pd.Series(ul_delays).describe())\n",
    "print(\"Summary stats: ul_thput\")\n",
    "print(pd.Series(ul_delays).describe())\n",
    "print(\"Summary stats: dl_thput\")\n",
    "print(pd.Series(ul_delays).describe())\n",
    "\n",
    "\n",
    "#=======================================\n",
    "# Plot histograms   \n",
    "#======================================= \n",
    "if histogram_plots:\n",
    "    xlimit=500\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.hist(ul_delays[ul_delays < xlimit], bins=50, color='red', edgecolor='black', label='< '+str(xlimit)+' ms'); plt.xlabel('UL delay (ms)'); plt.xlim(0, xlimit); plt.show\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.hist(dl_delays[dl_delays < xlimit], bins=50, color='blue', edgecolor='black', label='< '+str(xlimit)+' ms'); plt.xlabel('DL delay (ms)'); plt.xlim(0, xlimit); plt.show\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.hist(rtt_delays[rtt_delays < xlimit], bins=50, color='purple', edgecolor='black', label='< '+str(xlimit)+' ms'); plt.xlabel('RTT delay (ms)'); plt.xlim(0, xlimit); plt.show\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35815a08-fdbb-469d-a59a-e9448b071d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c1308-a14c-4d21-8ea3-cc4b6f793094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
