{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed58de6-5ac0-4bbb-95e7-c77e64dfaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "#%reset\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# DEBUG MODE\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "    \n",
    "from s3l_training import s3l_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb320c-c17f-40dd-8264-6dcbd0933f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random seed:  561\n",
      "GPU is available.\n",
      "1\n",
      "True\n",
      "12.1\n",
      "Concatenating runs:  range(1, 11)\n",
      "Time to read csv file for run:  3.077915906906128\n",
      "Loaded run 1\n",
      "Time to read csv file for run:  2.9825990200042725\n",
      "Loaded run 2\n",
      "Time to read csv file for run:  3.0426104068756104\n",
      "Loaded run 3\n",
      "Time to read csv file for run:  3.0151000022888184\n",
      "Loaded run 4\n",
      "Time to read csv file for run:  3.0426597595214844\n",
      "Loaded run 5\n",
      "Time to read csv file for run:  2.840830087661743\n",
      "Loaded run 6\n",
      "Time to read csv file for run:  3.0614089965820312\n",
      "Loaded run 7\n",
      "Time to read csv file for run:  3.081220865249634\n",
      "Loaded run 8\n",
      "Time to read csv file for run:  3.0392050743103027\n",
      "Loaded run 9\n",
      "Time to read csv file for run:  3.0053186416625977\n",
      "Loaded run 10\n",
      "pretrain_data, before removing rows that dont have traffic  (1799100, 102)\n",
      "pretrain_data, after removing rows that dont have traffic  (1799100, 102)\n",
      "X_pretrain  (1796746, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETERS:  {'loss_fn': 'MSELoss', 'metric': 'r2_score', 'hidden_dim': 300, 'max_epochs': 100, 'batch_size': 128, 'optim_hparams': {'lr': 0.0001, 'weight_decay': 5e-05}, 'encoder_depth': 4, 'head_depth': 2, 'dropout_rate': 0.1, 'noise_type': 'Swap', 'noise_ratio': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh rate:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                     | Type    | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | task_loss_fn             | MSELoss | 0      | train\n",
      "1 | mask_loss_fn             | BCELoss | 0      | train\n",
      "2 | categorical_feature_loss | BCELoss | 0      | train\n",
      "3 | continuous_feature_loss  | MSELoss | 0      | train\n",
      "4 | model                    | DAE     | 584 K  | train\n",
      "-------------------------------------------------------------\n",
      "584 K     Trainable params\n",
      "0         Non-trainable params\n",
      "584 K     Total params\n",
      "2.338     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████| 12704/12704 [02:26<00:00, 86.74it/s]\n",
      "Epoch 1: 100%|███████████████| 12704/12704 [02:30<00:00, 84.44it/s, train_loss=1.000, val_loss=0.838]\u001b[A\n",
      "Epoch 2: 100%|███████████████| 12704/12704 [02:25<00:00, 87.03it/s, train_loss=0.883, val_loss=0.804]\u001b[A\n",
      "Epoch 3: 100%|███████████████| 12704/12704 [02:15<00:00, 93.85it/s, train_loss=0.859, val_loss=0.789]\u001b[A\n",
      "Epoch 4: 100%|███████████████| 12704/12704 [02:15<00:00, 93.59it/s, train_loss=0.843, val_loss=0.779]\u001b[A\n",
      "Epoch 5: 100%|███████████████| 12704/12704 [02:16<00:00, 93.31it/s, train_loss=0.832, val_loss=0.767]\u001b[A\n",
      "Epoch 6: 100%|███████████████| 12704/12704 [02:13<00:00, 94.86it/s, train_loss=0.821, val_loss=0.753]\u001b[A\n",
      "Epoch 7: 100%|███████████████| 12704/12704 [02:20<00:00, 90.25it/s, train_loss=0.813, val_loss=0.756]\u001b[A\n",
      "Epoch 8: 100%|███████████████| 12704/12704 [02:20<00:00, 90.24it/s, train_loss=0.805, val_loss=0.740]\u001b[A\n",
      "Epoch 9: 100%|███████████████| 12704/12704 [02:20<00:00, 90.32it/s, train_loss=0.797, val_loss=0.734]\u001b[A\n",
      "Epoch 10: 100%|██████████████| 12704/12704 [02:20<00:00, 90.31it/s, train_loss=0.789, val_loss=0.754]\u001b[A\n",
      "Epoch 11: 100%|██████████████| 12704/12704 [02:20<00:00, 90.55it/s, train_loss=0.782, val_loss=0.714]\u001b[A\n",
      "Epoch 12: 100%|██████████████| 12704/12704 [02:21<00:00, 89.94it/s, train_loss=0.775, val_loss=0.713]\u001b[A\n",
      "Epoch 13: 100%|██████████████| 12704/12704 [02:21<00:00, 89.81it/s, train_loss=0.768, val_loss=0.705]\u001b[A\n",
      "Epoch 14: 100%|██████████████| 12704/12704 [02:20<00:00, 90.12it/s, train_loss=0.763, val_loss=0.697]\u001b[A\n",
      "Epoch 15: 100%|██████████████| 12704/12704 [02:21<00:00, 89.72it/s, train_loss=0.755, val_loss=0.694]\u001b[A\n",
      "Epoch 16: 100%|██████████████| 12704/12704 [02:20<00:00, 90.27it/s, train_loss=0.752, val_loss=0.685]\u001b[A\n",
      "Epoch 17: 100%|██████████████| 12704/12704 [02:20<00:00, 90.60it/s, train_loss=0.747, val_loss=0.678]\u001b[A\n",
      "Epoch 18: 100%|██████████████| 12704/12704 [02:20<00:00, 90.69it/s, train_loss=0.743, val_loss=0.679]\u001b[A\n",
      "Epoch 19: 100%|██████████████| 12704/12704 [02:20<00:00, 90.12it/s, train_loss=0.737, val_loss=0.678]\u001b[A\n",
      "Epoch 20: 100%|██████████████| 12704/12704 [02:21<00:00, 89.68it/s, train_loss=0.731, val_loss=0.663]\u001b[A\n",
      "Epoch 21: 100%|██████████████| 12704/12704 [02:20<00:00, 90.18it/s, train_loss=0.728, val_loss=0.661]\u001b[A\n",
      "Epoch 22: 100%|██████████████| 12704/12704 [02:20<00:00, 90.49it/s, train_loss=0.722, val_loss=0.661]\u001b[A\n",
      "Epoch 23: 100%|██████████████| 12704/12704 [02:20<00:00, 90.31it/s, train_loss=0.718, val_loss=0.647]\u001b[A\n",
      "Epoch 24: 100%|██████████████| 12704/12704 [02:20<00:00, 90.67it/s, train_loss=0.714, val_loss=0.646]\u001b[A\n",
      "Epoch 25: 100%|██████████████| 12704/12704 [02:21<00:00, 89.93it/s, train_loss=0.710, val_loss=0.640]\u001b[A\n",
      "Epoch 26: 100%|██████████████| 12704/12704 [02:21<00:00, 89.60it/s, train_loss=0.707, val_loss=0.642]\u001b[A\n",
      "Epoch 27: 100%|██████████████| 12704/12704 [02:20<00:00, 90.12it/s, train_loss=0.704, val_loss=0.637]\u001b[A\n",
      "Epoch 28: 100%|██████████████| 12704/12704 [02:20<00:00, 90.69it/s, train_loss=0.701, val_loss=0.634]\u001b[A\n",
      "Epoch 29: 100%|██████████████| 12704/12704 [02:21<00:00, 89.55it/s, train_loss=0.698, val_loss=0.636]\u001b[A\n",
      "Epoch 30: 100%|██████████████| 12704/12704 [02:19<00:00, 90.76it/s, train_loss=0.696, val_loss=0.626]\u001b[A\n",
      "Epoch 31: 100%|██████████████| 12704/12704 [02:19<00:00, 90.90it/s, train_loss=0.693, val_loss=0.622]\u001b[A\n",
      "Epoch 32: 100%|██████████████| 12704/12704 [02:20<00:00, 90.68it/s, train_loss=0.690, val_loss=0.618]\u001b[A\n",
      "Epoch 33: 100%|██████████████| 12704/12704 [02:21<00:00, 90.06it/s, train_loss=0.687, val_loss=0.615]\u001b[A\n",
      "Epoch 34: 100%|██████████████| 12704/12704 [02:19<00:00, 90.91it/s, train_loss=0.684, val_loss=0.616]\u001b[A\n",
      "Epoch 35: 100%|██████████████| 12704/12704 [02:19<00:00, 91.38it/s, train_loss=0.683, val_loss=0.613]\u001b[A\n",
      "Epoch 36: 100%|██████████████| 12704/12704 [02:20<00:00, 90.32it/s, train_loss=0.679, val_loss=0.607]\u001b[A\n",
      "Epoch 37: 100%|██████████████| 12704/12704 [02:19<00:00, 90.82it/s, train_loss=0.679, val_loss=0.620]\u001b[A\n",
      "Epoch 38: 100%|██████████████| 12704/12704 [02:20<00:00, 90.40it/s, train_loss=0.675, val_loss=0.606]\u001b[A\n",
      "Epoch 39: 100%|██████████████| 12704/12704 [02:21<00:00, 90.09it/s, train_loss=0.674, val_loss=0.603]\u001b[A\n",
      "Epoch 40: 100%|██████████████| 12704/12704 [02:20<00:00, 90.71it/s, train_loss=0.671, val_loss=0.601]\u001b[A\n",
      "Epoch 41: 100%|██████████████| 12704/12704 [02:21<00:00, 89.95it/s, train_loss=0.671, val_loss=0.601]\u001b[A\n",
      "Epoch 42: 100%|██████████████| 12704/12704 [02:21<00:00, 90.10it/s, train_loss=0.670, val_loss=0.600]\u001b[A\n",
      "Epoch 43: 100%|██████████████| 12704/12704 [02:19<00:00, 90.85it/s, train_loss=0.666, val_loss=0.594]\u001b[A\n",
      "Epoch 44: 100%|██████████████| 12704/12704 [02:20<00:00, 90.73it/s, train_loss=0.667, val_loss=0.594]\u001b[A\n",
      "Epoch 45: 100%|██████████████| 12704/12704 [02:21<00:00, 89.96it/s, train_loss=0.665, val_loss=0.599]\u001b[A\n",
      "Epoch 46: 100%|██████████████| 12704/12704 [02:21<00:00, 89.73it/s, train_loss=0.662, val_loss=0.595]\u001b[A\n",
      "Epoch 47: 100%|██████████████| 12704/12704 [02:21<00:00, 89.94it/s, train_loss=0.661, val_loss=0.589]\u001b[A\n",
      "Epoch 48: 100%|██████████████| 12704/12704 [02:20<00:00, 90.40it/s, train_loss=0.659, val_loss=0.591]\u001b[A\n",
      "Epoch 49: 100%|██████████████| 12704/12704 [02:20<00:00, 90.35it/s, train_loss=0.660, val_loss=0.588]\u001b[A\n",
      "Epoch 50: 100%|██████████████| 12704/12704 [02:20<00:00, 90.24it/s, train_loss=0.657, val_loss=0.588]\u001b[A\n",
      "Epoch 51: 100%|██████████████| 12704/12704 [02:20<00:00, 90.33it/s, train_loss=0.655, val_loss=0.583]\u001b[A\n",
      "Epoch 52: 100%|██████████████| 12704/12704 [02:20<00:00, 90.22it/s, train_loss=0.656, val_loss=0.588]\u001b[A\n",
      "Epoch 53: 100%|██████████████| 12704/12704 [02:19<00:00, 91.14it/s, train_loss=0.655, val_loss=0.584]\u001b[A\n",
      "Epoch 54: 100%|██████████████| 12704/12704 [02:20<00:00, 90.35it/s, train_loss=0.654, val_loss=0.580]\u001b[A\n",
      "Epoch 55: 100%|██████████████| 12704/12704 [02:20<00:00, 90.72it/s, train_loss=0.652, val_loss=0.581]\u001b[A\n",
      "Epoch 56: 100%|██████████████| 12704/12704 [02:20<00:00, 90.51it/s, train_loss=0.651, val_loss=0.583]\u001b[A\n",
      "Epoch 57: 100%|██████████████| 12704/12704 [02:20<00:00, 90.22it/s, train_loss=0.649, val_loss=0.584]\u001b[A\n",
      "Epoch 58: 100%|██████████████| 12704/12704 [02:20<00:00, 90.37it/s, train_loss=0.649, val_loss=0.576]\u001b[A\n",
      "Epoch 59: 100%|██████████████| 12704/12704 [02:19<00:00, 90.92it/s, train_loss=0.648, val_loss=0.583]\u001b[A\n",
      "Epoch 60: 100%|██████████████| 12704/12704 [02:20<00:00, 90.44it/s, train_loss=0.647, val_loss=0.575]\u001b[A\n",
      "Epoch 61: 100%|██████████████| 12704/12704 [02:21<00:00, 90.02it/s, train_loss=0.646, val_loss=0.576]\u001b[A\n",
      "Epoch 62: 100%|██████████████| 12704/12704 [02:20<00:00, 90.54it/s, train_loss=0.645, val_loss=0.578]\u001b[A\n",
      "Epoch 63: 100%|██████████████| 12704/12704 [02:20<00:00, 90.58it/s, train_loss=0.644, val_loss=0.576]\u001b[A\n",
      "Epoch 64: 100%|██████████████| 12704/12704 [02:20<00:00, 90.44it/s, train_loss=0.643, val_loss=0.578]\u001b[A\n",
      "Epoch 65: 100%|██████████████| 12704/12704 [02:21<00:00, 89.77it/s, train_loss=0.642, val_loss=0.583]\u001b[A\n",
      "Epoch 66: 100%|██████████████| 12704/12704 [02:20<00:00, 90.52it/s, train_loss=0.641, val_loss=0.572]\u001b[A\n",
      "Epoch 67: 100%|██████████████| 12704/12704 [02:20<00:00, 90.19it/s, train_loss=0.640, val_loss=0.569]\u001b[A\n",
      "Epoch 68: 100%|██████████████| 12704/12704 [02:19<00:00, 91.00it/s, train_loss=0.640, val_loss=0.574]\u001b[A\n",
      "Epoch 69: 100%|██████████████| 12704/12704 [02:20<00:00, 90.47it/s, train_loss=0.638, val_loss=0.584]\u001b[A\n",
      "Epoch 70: 100%|██████████████| 12704/12704 [02:20<00:00, 90.56it/s, train_loss=0.639, val_loss=0.571]\u001b[A\n",
      "Epoch 71: 100%|██████████████| 12704/12704 [02:21<00:00, 90.07it/s, train_loss=0.638, val_loss=0.568]\u001b[A\n",
      "Epoch 72: 100%|██████████████| 12704/12704 [02:19<00:00, 91.27it/s, train_loss=0.638, val_loss=0.573]\u001b[A\n",
      "Epoch 73: 100%|██████████████| 12704/12704 [02:20<00:00, 90.56it/s, train_loss=0.637, val_loss=0.572]\u001b[A\n",
      "Epoch 74: 100%|██████████████| 12704/12704 [02:21<00:00, 90.01it/s, train_loss=0.637, val_loss=0.574]\u001b[A\n",
      "Epoch 75: 100%|██████████████| 12704/12704 [02:21<00:00, 89.53it/s, train_loss=0.637, val_loss=0.569]\u001b[A\n",
      "Epoch 76: 100%|██████████████| 12704/12704 [02:21<00:00, 89.69it/s, train_loss=0.637, val_loss=0.568]\u001b[A\n",
      "Epoch 77: 100%|██████████████| 12704/12704 [02:20<00:00, 90.33it/s, train_loss=0.635, val_loss=0.568]\u001b[A\n",
      "Epoch 78: 100%|██████████████| 12704/12704 [02:21<00:00, 90.08it/s, train_loss=0.634, val_loss=0.573]\u001b[A\n",
      "Epoch 79: 100%|██████████████| 12704/12704 [02:20<00:00, 90.38it/s, train_loss=0.634, val_loss=0.568]\u001b[A\n",
      "Epoch 80: 100%|██████████████| 12704/12704 [02:20<00:00, 90.53it/s, train_loss=0.634, val_loss=0.567]\u001b[A\n",
      "Epoch 81: 100%|██████████████| 12704/12704 [02:21<00:00, 89.72it/s, train_loss=0.632, val_loss=0.565]\u001b[A\n",
      "Epoch 82: 100%|██████████████| 12704/12704 [02:20<00:00, 90.59it/s, train_loss=0.633, val_loss=0.565]\u001b[A\n",
      "Epoch 83: 100%|██████████████| 12704/12704 [02:20<00:00, 90.70it/s, train_loss=0.632, val_loss=0.562]\u001b[A\n",
      "Epoch 84: 100%|██████████████| 12704/12704 [02:19<00:00, 90.84it/s, train_loss=0.631, val_loss=0.565]\u001b[A\n",
      "Epoch 85: 100%|██████████████| 12704/12704 [02:20<00:00, 90.38it/s, train_loss=0.630, val_loss=0.561]\u001b[A\n",
      "Epoch 86: 100%|██████████████| 12704/12704 [02:21<00:00, 89.85it/s, train_loss=0.631, val_loss=0.566]\u001b[A\n",
      "Epoch 87: 100%|██████████████| 12704/12704 [02:20<00:00, 90.60it/s, train_loss=0.633, val_loss=0.563]\u001b[A\n",
      "Epoch 88: 100%|██████████████| 12704/12704 [02:20<00:00, 90.22it/s, train_loss=0.629, val_loss=0.568]\u001b[A\n",
      "Epoch 89: 100%|██████████████| 12704/12704 [02:19<00:00, 90.86it/s, train_loss=0.628, val_loss=0.561]\u001b[A\n",
      "Epoch 90: 100%|██████████████| 12704/12704 [02:21<00:00, 89.94it/s, train_loss=0.627, val_loss=0.560]\u001b[A\n",
      "Epoch 91: 100%|██████████████| 12704/12704 [02:19<00:00, 90.75it/s, train_loss=0.627, val_loss=0.561]\u001b[A\n",
      "Epoch 92: 100%|██████████████| 12704/12704 [02:20<00:00, 90.17it/s, train_loss=0.628, val_loss=0.563]\u001b[A\n",
      "Epoch 93: 100%|██████████████| 12704/12704 [02:21<00:00, 90.02it/s, train_loss=0.626, val_loss=0.572]\u001b[A\n",
      "Epoch 94: 100%|██████████████| 12704/12704 [02:20<00:00, 90.19it/s, train_loss=0.627, val_loss=0.563]\u001b[A\n",
      "Epoch 95: 100%|██████████████| 12704/12704 [02:22<00:00, 89.04it/s, train_loss=0.625, val_loss=0.556]\u001b[A\n",
      "Epoch 96: 100%|██████████████| 12704/12704 [02:21<00:00, 89.49it/s, train_loss=0.624, val_loss=0.556]\u001b[A\n",
      "Epoch 97: 100%|██████████████| 12704/12704 [02:20<00:00, 90.17it/s, train_loss=0.625, val_loss=0.557]\u001b[A\n",
      "Epoch 98:   8%|█▎             | 1060/12704 [00:12<02:15, 85.74it/s, train_loss=0.623, val_loss=0.554]\u001b[A"
     ]
    }
   ],
   "source": [
    "s3l_training(pretrain=True, # if True First Phase training\n",
    "             use_pretrained_model=False, # if True Second Phase learning\n",
    "             pt_type='dae', \n",
    "             pt_folder='FP7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7160f9-4db4-4688-9556-ba884a04eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
