{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed58de6-5ac0-4bbb-95e7-c77e64dfaf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload\n",
    "#%reset\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# DEBUG MODE\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "    \n",
    "from s3l_training import s3l_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26eb320c-c17f-40dd-8264-6dcbd0933f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random seed:  561\n",
      "GPU is available.\n",
      "1\n",
      "True\n",
      "12.1\n",
      "Concatenating runs:  range(1, 11)\n",
      "Time to read csv file for run:  3.679764986038208\n",
      "Loaded run 1\n",
      "Time to read csv file for run:  3.76300048828125\n",
      "Loaded run 2\n",
      "Time to read csv file for run:  3.7833383083343506\n",
      "Loaded run 3\n",
      "Time to read csv file for run:  3.5556836128234863\n",
      "Loaded run 4\n",
      "Time to read csv file for run:  3.467864751815796\n",
      "Loaded run 5\n",
      "Time to read csv file for run:  3.3824970722198486\n",
      "Loaded run 6\n",
      "Time to read csv file for run:  3.6437361240386963\n",
      "Loaded run 7\n",
      "Time to read csv file for run:  3.4446282386779785\n",
      "Loaded run 8\n",
      "Time to read csv file for run:  3.426501512527466\n",
      "Loaded run 9\n",
      "Time to read csv file for run:  3.430298328399658\n",
      "Loaded run 10\n",
      "cell_conn_type\n",
      "[0 1]\n",
      "categorical_cols:  ['cell_conn_type']\n",
      "(1796746, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621562, 92)\n",
      "(89838, 92)\n",
      "(85346, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh rate:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                   | Type      | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | task_loss_fn           | MSELoss   | 0      | train\n",
      "1 | reconstruction_loss_fn | MSELoss   | 0      | train\n",
      "2 | model                  | SwitchTab | 1.9 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.461     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975]\n",
      "Epoch 1: 100%|███████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975, train_loss=0.863, val_loss=0.784]\u001b[A\n",
      "Epoch 2: 100%|███████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975, train_loss=0.795, val_loss=0.775]\u001b[A\n",
      "Epoch 3: 100%|███████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975, train_loss=0.786, val_loss=0.769]\u001b[A\n",
      "Epoch 4: 100%|███████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975, train_loss=0.780, val_loss=0.771]\u001b[A\n",
      "Epoch 5: 100%|███████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975, train_loss=0.778, val_loss=0.765]\u001b[A\n",
      "Epoch 6: 100%|███████████████████████████████████████████| 13371/13371 [21:07<00:00, 10.55it/s, v_num=975, train_loss=0.777, val_loss=0.770]\u001b[A\n",
      "Epoch 7: 100%|███████████████████████████████████████████| 13371/13371 [21:07<00:00, 10.55it/s, v_num=975, train_loss=0.776, val_loss=0.771]\u001b[A\n",
      "Epoch 8: 100%|███████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975, train_loss=0.771, val_loss=0.757]\u001b[A\n",
      "Epoch 9: 100%|███████████████████████████████████████████| 13371/13371 [21:07<00:00, 10.55it/s, v_num=975, train_loss=0.770, val_loss=0.763]\u001b[A\n",
      "Epoch 10: 100%|██████████████████████████████████████████| 13371/13371 [21:07<00:00, 10.55it/s, v_num=975, train_loss=0.769, val_loss=0.758]\u001b[A\n",
      "Epoch 11: 100%|██████████████████████████████████████████| 13371/13371 [20:19<00:00, 10.96it/s, v_num=975, train_loss=0.775, val_loss=0.760]\u001b[A\n",
      "Epoch 12: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.770, val_loss=0.761]\u001b[A\n",
      "Epoch 13: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.772, val_loss=0.764]\u001b[A\n",
      "Epoch 14: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.774, val_loss=0.753]\u001b[A\n",
      "Epoch 15: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.769, val_loss=0.757]\u001b[A\n",
      "Epoch 16: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.770, val_loss=0.763]\u001b[A\n",
      "Epoch 17: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.766, val_loss=0.758]\u001b[A\n",
      "Epoch 18: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.37it/s, v_num=975, train_loss=0.769, val_loss=0.755]\u001b[A\n",
      "Epoch 19: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.769, val_loss=0.755]\u001b[A\n",
      "Epoch 20: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.771, val_loss=0.759]\u001b[A\n",
      "Epoch 21: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.767, val_loss=0.761]\u001b[A\n",
      "Epoch 22: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.767, val_loss=0.754]\u001b[A\n",
      "Epoch 23: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.767, val_loss=0.751]\u001b[A\n",
      "Epoch 24: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.771, val_loss=0.758]\u001b[A\n",
      "Epoch 25: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.767, val_loss=0.766]\u001b[A\n",
      "Epoch 26: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.766, val_loss=0.761]\u001b[A\n",
      "Epoch 27: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.768, val_loss=0.758]\u001b[A\n",
      "Epoch 28: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.765, val_loss=0.758]\u001b[A\n",
      "Epoch 29: 100%|██████████████████████████████████████████| 13371/13371 [18:01<00:00, 12.37it/s, v_num=975, train_loss=0.763, val_loss=0.758]\u001b[A\n",
      "Epoch 30: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.37it/s, v_num=975, train_loss=0.764, val_loss=0.766]\u001b[A\n",
      "Epoch 31: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.764, val_loss=0.754]\u001b[A\n",
      "Epoch 32: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.768, val_loss=0.752]\u001b[A\n",
      "Epoch 33: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.771, val_loss=0.759]\u001b[A\n",
      "Epoch 34: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.765, val_loss=0.758]\u001b[A\n",
      "Epoch 35: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.768, val_loss=0.758]\u001b[A\n",
      "Epoch 36: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.762, val_loss=0.748]\u001b[A\n",
      "Epoch 37: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.764, val_loss=0.752]\u001b[A\n",
      "Epoch 38: 100%|██████████████████████████████████████████| 13371/13371 [18:01<00:00, 12.36it/s, v_num=975, train_loss=0.767, val_loss=0.748]\u001b[A\n",
      "Epoch 39: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.762, val_loss=0.758]\u001b[A\n",
      "Epoch 40: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.761, val_loss=0.760]\u001b[A\n",
      "Epoch 41: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.766, val_loss=0.755]\u001b[A\n",
      "Epoch 42: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.38it/s, v_num=975, train_loss=0.762, val_loss=0.751]\u001b[A\n",
      "Epoch 43: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.766, val_loss=0.752]\u001b[A\n",
      "Epoch 44: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.767, val_loss=0.752]\u001b[A\n",
      "Epoch 45: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.771, val_loss=0.757]\u001b[A\n",
      "Epoch 46: 100%|██████████████████████████████████████████| 13371/13371 [17:58<00:00, 12.39it/s, v_num=975, train_loss=0.769, val_loss=0.750]\u001b[A\n",
      "Epoch 47: 100%|██████████████████████████████████████████| 13371/13371 [17:58<00:00, 12.40it/s, v_num=975, train_loss=0.770, val_loss=0.754]\u001b[A\n",
      "Epoch 48: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.766, val_loss=0.753]\u001b[A\n",
      "Epoch 49: 100%|██████████████████████████████████████████| 13371/13371 [17:58<00:00, 12.39it/s, v_num=975, train_loss=0.766, val_loss=0.750]\u001b[A\n",
      "Epoch 50: 100%|██████████████████████████████████████████| 13371/13371 [17:59<00:00, 12.39it/s, v_num=975, train_loss=0.767, val_loss=0.758]\u001b[A\n",
      "Epoch 51: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.41it/s, v_num=975, train_loss=0.763, val_loss=0.755]\u001b[A\n",
      "Epoch 52: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.40it/s, v_num=975, train_loss=0.767, val_loss=0.749]\u001b[A\n",
      "Epoch 53: 100%|██████████████████████████████████████████| 13371/13371 [18:34<00:00, 12.00it/s, v_num=975, train_loss=0.765, val_loss=0.753]\u001b[A\n",
      "Epoch 54: 100%|██████████████████████████████████████████| 13371/13371 [18:59<00:00, 11.73it/s, v_num=975, train_loss=0.764, val_loss=0.755]\u001b[A\n",
      "Epoch 55: 100%|██████████████████████████████████████████| 13371/13371 [19:09<00:00, 11.64it/s, v_num=975, train_loss=0.769, val_loss=0.752]\u001b[A\n",
      "Epoch 56: 100%|██████████████████████████████████████████| 13371/13371 [19:21<00:00, 11.52it/s, v_num=975, train_loss=0.764, val_loss=0.756]\u001b[A\n",
      "Epoch 57: 100%|██████████████████████████████████████████| 13371/13371 [19:24<00:00, 11.49it/s, v_num=975, train_loss=0.762, val_loss=0.746]\u001b[A\n",
      "Epoch 58: 100%|██████████████████████████████████████████| 13371/13371 [19:54<00:00, 11.19it/s, v_num=975, train_loss=0.762, val_loss=0.754]\u001b[A\n",
      "Epoch 59: 100%|██████████████████████████████████████████| 13371/13371 [20:32<00:00, 10.85it/s, v_num=975, train_loss=0.759, val_loss=0.751]\u001b[A\n",
      "Epoch 60: 100%|██████████████████████████████████████████| 13371/13371 [20:30<00:00, 10.87it/s, v_num=975, train_loss=0.765, val_loss=0.751]\u001b[A\n",
      "Epoch 61: 100%|██████████████████████████████████████████| 13371/13371 [20:39<00:00, 10.78it/s, v_num=975, train_loss=0.763, val_loss=0.753]\u001b[A\n",
      "Epoch 62: 100%|██████████████████████████████████████████| 13371/13371 [20:48<00:00, 10.71it/s, v_num=975, train_loss=0.762, val_loss=0.751]\u001b[A\n",
      "Epoch 63: 100%|██████████████████████████████████████████| 13371/13371 [20:57<00:00, 10.63it/s, v_num=975, train_loss=0.762, val_loss=0.755]\u001b[A\n",
      "Epoch 64: 100%|██████████████████████████████████████████| 13371/13371 [21:08<00:00, 10.54it/s, v_num=975, train_loss=0.766, val_loss=0.750]\u001b[A\n",
      "Epoch 65: 100%|██████████████████████████████████████████| 13371/13371 [20:40<00:00, 10.78it/s, v_num=975, train_loss=0.765, val_loss=0.750]\u001b[A\n",
      "Epoch 66: 100%|██████████████████████████████████████████| 13371/13371 [20:29<00:00, 10.88it/s, v_num=975, train_loss=0.760, val_loss=0.755]\u001b[A\n",
      "Epoch 67: 100%|██████████████████████████████████████████| 13371/13371 [19:49<00:00, 11.24it/s, v_num=975, train_loss=0.764, val_loss=0.745]\u001b[A\n",
      "Epoch 68: 100%|██████████████████████████████████████████| 13371/13371 [19:46<00:00, 11.27it/s, v_num=975, train_loss=0.761, val_loss=0.756]\u001b[A\n",
      "Epoch 69: 100%|██████████████████████████████████████████| 13371/13371 [19:49<00:00, 11.24it/s, v_num=975, train_loss=0.764, val_loss=0.748]\u001b[A\n",
      "Epoch 70: 100%|██████████████████████████████████████████| 13371/13371 [19:07<00:00, 11.65it/s, v_num=975, train_loss=0.765, val_loss=0.749]\u001b[A\n",
      "Epoch 71: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.41it/s, v_num=975, train_loss=0.768, val_loss=0.744]\u001b[A\n",
      "Epoch 72: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.40it/s, v_num=975, train_loss=0.758, val_loss=0.757]\u001b[A\n",
      "Epoch 73: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.41it/s, v_num=975, train_loss=0.764, val_loss=0.750]\u001b[A\n",
      "Epoch 74: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.41it/s, v_num=975, train_loss=0.760, val_loss=0.747]\u001b[A\n",
      "Epoch 75: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.40it/s, v_num=975, train_loss=0.759, val_loss=0.751]\u001b[A\n",
      "Epoch 76: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.41it/s, v_num=975, train_loss=0.760, val_loss=0.756]\u001b[A\n",
      "Epoch 77: 100%|██████████████████████████████████████████| 13371/13371 [17:58<00:00, 12.40it/s, v_num=975, train_loss=0.757, val_loss=0.755]\u001b[A\n",
      "Epoch 78: 100%|██████████████████████████████████████████| 13371/13371 [17:58<00:00, 12.40it/s, v_num=975, train_loss=0.761, val_loss=0.757]\u001b[A\n",
      "Epoch 79: 100%|██████████████████████████████████████████| 13371/13371 [25:13<00:00,  8.83it/s, v_num=975, train_loss=0.760, val_loss=0.748]\u001b[A\n",
      "Epoch 80: 100%|██████████████████████████████████████████| 13371/13371 [31:14<00:00,  7.13it/s, v_num=975, train_loss=0.761, val_loss=0.755]\u001b[A\n",
      "Epoch 81: 100%|██████████████████████████████████████████| 13371/13371 [31:19<00:00,  7.11it/s, v_num=975, train_loss=0.760, val_loss=0.754]\u001b[A\n",
      "Epoch 82: 100%|██████████████████████████████████████████| 13371/13371 [31:57<00:00,  6.97it/s, v_num=975, train_loss=0.761, val_loss=0.762]\u001b[A\n",
      "Epoch 83: 100%|██████████████████████████████████████████| 13371/13371 [32:14<00:00,  6.91it/s, v_num=975, train_loss=0.759, val_loss=0.756]\u001b[A\n",
      "Epoch 84: 100%|██████████████████████████████████████████| 13371/13371 [32:29<00:00,  6.86it/s, v_num=975, train_loss=0.762, val_loss=0.751]\u001b[A\n",
      "Epoch 85: 100%|██████████████████████████████████████████| 13371/13371 [32:51<00:00,  6.78it/s, v_num=975, train_loss=0.762, val_loss=0.756]\u001b[A\n",
      "Epoch 86: 100%|██████████████████████████████████████████| 13371/13371 [32:57<00:00,  6.76it/s, v_num=975, train_loss=0.759, val_loss=0.750]\u001b[A\n",
      "Epoch 87: 100%|██████████████████████████████████████████| 13371/13371 [32:31<00:00,  6.85it/s, v_num=975, train_loss=0.767, val_loss=0.755]\u001b[A\n",
      "Epoch 88: 100%|██████████████████████████████████████████| 13371/13371 [31:53<00:00,  6.99it/s, v_num=975, train_loss=0.761, val_loss=0.752]\u001b[A\n",
      "Epoch 89: 100%|██████████████████████████████████████████| 13371/13371 [31:59<00:00,  6.97it/s, v_num=975, train_loss=0.771, val_loss=0.751]\u001b[A\n",
      "Epoch 90: 100%|██████████████████████████████████████████| 13371/13371 [31:34<00:00,  7.06it/s, v_num=975, train_loss=0.764, val_loss=0.746]\u001b[A\n",
      "Epoch 91: 100%|██████████████████████████████████████████| 13371/13371 [30:31<00:00,  7.30it/s, v_num=975, train_loss=0.765, val_loss=0.751]\u001b[A\n",
      "Epoch 92: 100%|██████████████████████████████████████████| 13371/13371 [30:33<00:00,  7.29it/s, v_num=975, train_loss=0.760, val_loss=0.759]\u001b[A\n",
      "Epoch 93: 100%|██████████████████████████████████████████| 13371/13371 [30:33<00:00,  7.29it/s, v_num=975, train_loss=0.760, val_loss=0.751]\u001b[A\n",
      "Epoch 94: 100%|██████████████████████████████████████████| 13371/13371 [30:32<00:00,  7.30it/s, v_num=975, train_loss=0.764, val_loss=0.745]\u001b[A\n",
      "Epoch 95: 100%|██████████████████████████████████████████| 13371/13371 [30:35<00:00,  7.29it/s, v_num=975, train_loss=0.764, val_loss=0.753]\u001b[A\n",
      "Epoch 96: 100%|██████████████████████████████████████████| 13371/13371 [30:35<00:00,  7.28it/s, v_num=975, train_loss=0.762, val_loss=0.755]\u001b[A\n",
      "Epoch 97: 100%|██████████████████████████████████████████| 13371/13371 [20:35<00:00, 10.82it/s, v_num=975, train_loss=0.762, val_loss=0.759]\u001b[A\n",
      "Epoch 98: 100%|██████████████████████████████████████████| 13371/13371 [18:00<00:00, 12.38it/s, v_num=975, train_loss=0.760, val_loss=0.745]\u001b[A\n",
      "Epoch 99: 100%|██████████████████████████████████████████| 13371/13371 [17:57<00:00, 12.41it/s, v_num=975, train_loss=0.762, val_loss=0.759]\u001b[A\n",
      "Epoch 99: 100%|██████████████████████████████████████████| 13371/13371 [18:21<00:00, 12.14it/s, v_num=975, train_loss=0.763, val_loss=0.752]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████████████████████████████████████| 13371/13371 [18:21<00:00, 12.14it/s, v_num=975, train_loss=0.763, val_loss=0.752]\n",
      "DONE SAVING PRETRAINED MODEL\n",
      "   | Name                                                                     | Type               | Params | Mode \n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "0  | task_loss_fn                                                             | MSELoss            | 0      | train\n",
      "1  | reconstruction_loss_fn                                                   | MSELoss            | 0      | train\n",
      "2  | model                                                                    | SwitchTab          | 1.9 M  | train\n",
      "3  | model._SwitchTab__encoder                                                | Encoder            | 1.6 M  | train\n",
      "4  | model._SwitchTab__encoder.transformer                                    | FTTransformer      | 1.6 M  | train\n",
      "5  | model._SwitchTab__encoder.transformer.tokenizer                          | FeatureTokenizer   | 37.0 K | train\n",
      "6  | model._SwitchTab__encoder.transformer.tokenizer.cat_weights              | Embedding          | 0      | train\n",
      "7  | model._SwitchTab__encoder.transformer.backbone                           | Sequential         | 1.6 M  | train\n",
      "8  | model._SwitchTab__encoder.transformer.backbone.0                         | Transformer        | 402 K  | train\n",
      "9  | model._SwitchTab__encoder.transformer.backbone.0.block                   | ModuleDict         | 402 K  | train\n",
      "10 | model._SwitchTab__encoder.transformer.backbone.0.block.attention         | MultiheadAttention | 160 K  | train\n",
      "11 | model._SwitchTab__encoder.transformer.backbone.0.block.attention.W_qkv   | Linear             | 120 K  | train\n",
      "12 | model._SwitchTab__encoder.transformer.backbone.0.block.attention.W_out   | Linear             | 40.2 K | train\n",
      "13 | model._SwitchTab__encoder.transformer.backbone.0.block.attention.dropout | Dropout            | 0      | train\n",
      "14 | model._SwitchTab__encoder.transformer.backbone.0.block.linear0           | Linear             | 160 K  | train\n",
      "15 | model._SwitchTab__encoder.transformer.backbone.0.block.linear1           | Linear             | 80.2 K | train\n",
      "16 | model._SwitchTab__encoder.transformer.backbone.0.block.norm1             | LayerNorm          | 400    | train\n",
      "17 | model._SwitchTab__encoder.transformer.backbone.0.block.ffn_dropout       | Dropout            | 0      | train\n",
      "18 | model._SwitchTab__encoder.transformer.backbone.1                         | Transformer        | 402 K  | train\n",
      "19 | model._SwitchTab__encoder.transformer.backbone.1.block                   | ModuleDict         | 402 K  | train\n",
      "20 | model._SwitchTab__encoder.transformer.backbone.1.block.attention         | MultiheadAttention | 160 K  | train\n",
      "21 | model._SwitchTab__encoder.transformer.backbone.1.block.attention.W_qkv   | Linear             | 120 K  | train\n",
      "22 | model._SwitchTab__encoder.transformer.backbone.1.block.attention.W_out   | Linear             | 40.2 K | train\n",
      "23 | model._SwitchTab__encoder.transformer.backbone.1.block.attention.dropout | Dropout            | 0      | train\n",
      "24 | model._SwitchTab__encoder.transformer.backbone.1.block.linear0           | Linear             | 160 K  | train\n",
      "25 | model._SwitchTab__encoder.transformer.backbone.1.block.linear1           | Linear             | 80.2 K | train\n",
      "26 | model._SwitchTab__encoder.transformer.backbone.1.block.norm1             | LayerNorm          | 400    | train\n",
      "27 | model._SwitchTab__encoder.transformer.backbone.1.block.norm0             | LayerNorm          | 400    | train\n",
      "28 | model._SwitchTab__encoder.transformer.backbone.1.block.ffn_dropout       | Dropout            | 0      | train\n",
      "29 | model._SwitchTab__encoder.transformer.backbone.2                         | Transformer        | 402 K  | train\n",
      "30 | model._SwitchTab__encoder.transformer.backbone.2.block                   | ModuleDict         | 402 K  | train\n",
      "31 | model._SwitchTab__encoder.transformer.backbone.2.block.attention         | MultiheadAttention | 160 K  | train\n",
      "32 | model._SwitchTab__encoder.transformer.backbone.2.block.attention.W_qkv   | Linear             | 120 K  | train\n",
      "33 | model._SwitchTab__encoder.transformer.backbone.2.block.attention.W_out   | Linear             | 40.2 K | train\n",
      "34 | model._SwitchTab__encoder.transformer.backbone.2.block.attention.dropout | Dropout            | 0      | train\n",
      "35 | model._SwitchTab__encoder.transformer.backbone.2.block.linear0           | Linear             | 160 K  | train\n",
      "36 | model._SwitchTab__encoder.transformer.backbone.2.block.linear1           | Linear             | 80.2 K | train\n",
      "37 | model._SwitchTab__encoder.transformer.backbone.2.block.norm1             | LayerNorm          | 400    | train\n",
      "38 | model._SwitchTab__encoder.transformer.backbone.2.block.norm0             | LayerNorm          | 400    | train\n",
      "39 | model._SwitchTab__encoder.transformer.backbone.2.block.ffn_dropout       | Dropout            | 0      | train\n",
      "40 | model._SwitchTab__encoder.transformer.backbone.3                         | Transformer        | 402 K  | train\n",
      "41 | model._SwitchTab__encoder.transformer.backbone.3.block                   | ModuleDict         | 402 K  | train\n",
      "42 | model._SwitchTab__encoder.transformer.backbone.3.block.attention         | MultiheadAttention | 160 K  | train\n",
      "43 | model._SwitchTab__encoder.transformer.backbone.3.block.attention.W_qkv   | Linear             | 120 K  | train\n",
      "44 | model._SwitchTab__encoder.transformer.backbone.3.block.attention.W_out   | Linear             | 40.2 K | train\n",
      "45 | model._SwitchTab__encoder.transformer.backbone.3.block.attention.dropout | Dropout            | 0      | train\n",
      "46 | model._SwitchTab__encoder.transformer.backbone.3.block.linear0           | Linear             | 160 K  | train\n",
      "47 | model._SwitchTab__encoder.transformer.backbone.3.block.linear1           | Linear             | 80.2 K | train\n",
      "48 | model._SwitchTab__encoder.transformer.backbone.3.block.norm1             | LayerNorm          | 400    | train\n",
      "49 | model._SwitchTab__encoder.transformer.backbone.3.block.norm0             | LayerNorm          | 400    | train\n",
      "50 | model._SwitchTab__encoder.transformer.backbone.3.block.ffn_dropout       | Dropout            | 0      | train\n",
      "51 | model.projector_m                                                        | Projector          | 40.2 K | train\n",
      "52 | model.projector_m.linear                                                 | Linear             | 40.2 K | train\n",
      "53 | model.projector_m.activation                                             | SiLU               | 0      | train\n",
      "54 | model.projector_s                                                        | Projector          | 40.2 K | train\n",
      "55 | model.projector_s.linear                                                 | Linear             | 40.2 K | train\n",
      "56 | model.projector_s.activation                                             | SiLU               | 0      | train\n",
      "57 | model.decoder                                                            | Decoder            | 36.9 K | train\n",
      "58 | model.decoder.linear                                                     | Linear             | 36.9 K | train\n",
      "59 | model.decoder.activation                                                 | SiLU               | 0      | train\n",
      "60 | model.head                                                               | Linear             | 201    | train\n",
      "61 | model.one_layer_prediction_head                                          | Sequential         | 40.4 K | train\n",
      "62 | model.one_layer_prediction_head.head_linear_hid                          | Linear             | 40.2 K | train\n",
      "63 | model.one_layer_prediction_head.head_activation                          | ReLU               | 0      | train\n",
      "64 | model.one_layer_prediction_head.head_linear_out                          | Linear             | 201    | train\n",
      "65 | model.two_layer_prediction_head                                          | Sequential         | 60.4 K | train\n",
      "66 | model.two_layer_prediction_head.head_linear_hid1                         | Linear             | 40.2 K | train\n",
      "67 | model.two_layer_prediction_head.head_activation1                         | ReLU               | 0      | train\n",
      "68 | model.two_layer_prediction_head.head_linear_hid2                         | Linear             | 20.1 K | train\n",
      "69 | model.two_layer_prediction_head.head_activation2                         | ReLU               | 0      | train\n",
      "70 | model.two_layer_prediction_head.head_linear_out                          | Linear             | 101    | train\n",
      "71 | model.activation                                                         | SiLU               | 0      | train\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.461     Total estimated model params size (MB)\n",
      "DONE PRETRAINING\n"
     ]
    }
   ],
   "source": [
    "s3l_training(pretrain=True, # if True First Phase training\n",
    "             use_pretrained_model=False, # if True Second Phase learning\n",
    "             pt_type='switchtab', \n",
    "             pt_folder='FP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7160f9-4db4-4688-9556-ba884a04eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
