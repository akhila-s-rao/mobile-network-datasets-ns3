{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed58de6-5ac0-4bbb-95e7-c77e64dfaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "#%reset\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# DEBUG MODE\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "    \n",
    "from s3l_training import s3l_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26eb320c-c17f-40dd-8264-6dcbd0933f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random seed:  561\n",
      "GPU is available.\n",
      "1\n",
      "True\n",
      "12.1\n",
      "Concatenating runs:  range(1, 11)\n",
      "Time to read csv file for run:  3.0805447101593018\n",
      "Loaded run 1\n",
      "Time to read csv file for run:  2.9322493076324463\n",
      "Loaded run 2\n",
      "Time to read csv file for run:  2.9404962062835693\n",
      "Loaded run 3\n",
      "Time to read csv file for run:  2.9105777740478516\n",
      "Loaded run 4\n",
      "Time to read csv file for run:  2.9137699604034424\n",
      "Loaded run 5\n",
      "Time to read csv file for run:  2.759160041809082\n",
      "Loaded run 6\n",
      "Time to read csv file for run:  2.8949666023254395\n",
      "Loaded run 7\n",
      "Time to read csv file for run:  2.896120071411133\n",
      "Loaded run 8\n",
      "Time to read csv file for run:  2.893270969390869\n",
      "Loaded run 9\n",
      "Time to read csv file for run:  2.8366994857788086\n",
      "Loaded run 10\n",
      "(1796746, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621562, 92)\n",
      "(89838, 92)\n",
      "(85346, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh rate:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type      | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | task_loss_fn  | MSELoss   | 0      | train\n",
      "1 | joint_loss_fn | JointLoss | 0      | train\n",
      "2 | model         | SubTab    | 207 K  | train\n",
      "----------------------------------------------------\n",
      "207 K     Trainable params\n",
      "0         Non-trainable params\n",
      "207 K     Total params\n",
      "0.832     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████████████| 13371/13371 [07:37<00:00, 29.24it/s, v_num=1488]\n",
      "Epoch 1: 100%|██████| 13371/13371 [07:37<00:00, 29.23it/s, v_num=1488, train_loss=5.260, val_loss=5.110]\u001b[A\n",
      "Epoch 2: 100%|██████| 13371/13371 [07:38<00:00, 29.18it/s, v_num=1488, train_loss=5.080, val_loss=5.050]\u001b[A\n",
      "Epoch 3: 100%|██████| 13371/13371 [07:40<00:00, 29.01it/s, v_num=1488, train_loss=5.050, val_loss=5.040]\u001b[A\n",
      "Epoch 4: 100%|██████| 13371/13371 [07:34<00:00, 29.43it/s, v_num=1488, train_loss=5.040, val_loss=5.030]\u001b[A\n",
      "Epoch 5: 100%|██████| 13371/13371 [07:39<00:00, 29.12it/s, v_num=1488, train_loss=5.040, val_loss=5.020]\u001b[A\n",
      "Epoch 6: 100%|██████| 13371/13371 [07:36<00:00, 29.27it/s, v_num=1488, train_loss=5.030, val_loss=5.020]\u001b[A\n",
      "Epoch 7: 100%|██████| 13371/13371 [07:34<00:00, 29.41it/s, v_num=1488, train_loss=5.030, val_loss=5.020]\u001b[A\n",
      "Epoch 8: 100%|██████| 13371/13371 [07:34<00:00, 29.40it/s, v_num=1488, train_loss=5.020, val_loss=5.020]\u001b[A\n",
      "Epoch 9: 100%|██████| 13371/13371 [07:34<00:00, 29.45it/s, v_num=1488, train_loss=5.030, val_loss=5.010]\u001b[A\n",
      "Epoch 10: 100%|█████| 13371/13371 [07:42<00:00, 28.93it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 11: 100%|█████| 13371/13371 [07:39<00:00, 29.12it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 12: 100%|█████| 13371/13371 [07:44<00:00, 28.76it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 13: 100%|█████| 13371/13371 [07:39<00:00, 29.08it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 14: 100%|█████| 13371/13371 [07:40<00:00, 29.01it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 15: 100%|█████| 13371/13371 [07:39<00:00, 29.09it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 16: 100%|█████| 13371/13371 [07:38<00:00, 29.18it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 17: 100%|█████| 13371/13371 [07:36<00:00, 29.28it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 18: 100%|█████| 13371/13371 [07:36<00:00, 29.29it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 19: 100%|█████| 13371/13371 [07:38<00:00, 29.17it/s, v_num=1488, train_loss=5.020, val_loss=5.000]\u001b[A\n",
      "Epoch 20: 100%|█████| 13371/13371 [07:35<00:00, 29.35it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 21: 100%|█████| 13371/13371 [07:34<00:00, 29.41it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 22: 100%|█████| 13371/13371 [07:40<00:00, 29.06it/s, v_num=1488, train_loss=5.020, val_loss=5.010]\u001b[A\n",
      "Epoch 23: 100%|█████| 13371/13371 [07:37<00:00, 29.21it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 24: 100%|█████| 13371/13371 [07:38<00:00, 29.19it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 25: 100%|█████| 13371/13371 [07:39<00:00, 29.08it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 26: 100%|█████| 13371/13371 [07:37<00:00, 29.23it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 27: 100%|█████| 13371/13371 [07:35<00:00, 29.34it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 28: 100%|█████| 13371/13371 [07:34<00:00, 29.42it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 29: 100%|█████| 13371/13371 [07:36<00:00, 29.31it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 30: 100%|█████| 13371/13371 [07:35<00:00, 29.39it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 31: 100%|█████| 13371/13371 [07:34<00:00, 29.42it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 32: 100%|█████| 13371/13371 [07:37<00:00, 29.24it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 33: 100%|█████| 13371/13371 [07:35<00:00, 29.34it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 34: 100%|█████| 13371/13371 [07:40<00:00, 29.03it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 35: 100%|█████| 13371/13371 [07:33<00:00, 29.51it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 36: 100%|█████| 13371/13371 [07:35<00:00, 29.34it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 37: 100%|█████| 13371/13371 [07:37<00:00, 29.20it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 38: 100%|█████| 13371/13371 [07:38<00:00, 29.16it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 39: 100%|█████| 13371/13371 [07:38<00:00, 29.16it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 40: 100%|█████| 13371/13371 [07:37<00:00, 29.23it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 41: 100%|█████| 13371/13371 [07:36<00:00, 29.26it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 42: 100%|█████| 13371/13371 [07:36<00:00, 29.30it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 43: 100%|█████| 13371/13371 [07:38<00:00, 29.15it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 44: 100%|█████| 13371/13371 [07:35<00:00, 29.37it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 45: 100%|█████| 13371/13371 [07:35<00:00, 29.39it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 46: 100%|█████| 13371/13371 [07:36<00:00, 29.29it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 47: 100%|█████| 13371/13371 [07:35<00:00, 29.34it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 48: 100%|█████| 13371/13371 [07:35<00:00, 29.38it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 49: 100%|█████| 13371/13371 [07:39<00:00, 29.10it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 50: 100%|█████| 13371/13371 [07:40<00:00, 29.04it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 51: 100%|█████| 13371/13371 [07:37<00:00, 29.23it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 52: 100%|█████| 13371/13371 [07:34<00:00, 29.39it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 53: 100%|█████| 13371/13371 [07:38<00:00, 29.19it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 54: 100%|█████| 13371/13371 [07:35<00:00, 29.38it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 55: 100%|██| 13371/13371 [07:37<00:00, 29.21it/s, v_num=1488, train_loss=5.010, val_loss=5.000]   \u001b[A\n",
      "Epoch 56: 100%|██| 13371/13371 [07:39<00:00, 29.09it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 57: 100%|██| 13371/13371 [07:37<00:00, 29.20it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 58: 100%|██| 13371/13371 [07:36<00:00, 29.32it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 59: 100%|██| 13371/13371 [07:35<00:00, 29.32it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 60: 100%|██| 13371/13371 [07:48<00:00, 28.56it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 61: 100%|██| 13371/13371 [07:41<00:00, 28.96it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 62: 100%|██| 13371/13371 [07:41<00:00, 28.99it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 63: 100%|██| 13371/13371 [07:45<00:00, 28.73it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 64: 100%|██| 13371/13371 [07:40<00:00, 29.05it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 65: 100%|██| 13371/13371 [08:38<00:00, 25.77it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 66: 100%|██| 13371/13371 [09:08<00:00, 24.39it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 67: 100%|██| 13371/13371 [08:36<00:00, 25.87it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 68: 100%|██| 13371/13371 [08:57<00:00, 24.90it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 69: 100%|██| 13371/13371 [08:47<00:00, 25.32it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 70: 100%|██| 13371/13371 [08:57<00:00, 24.88it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 71: 100%|██| 13371/13371 [08:59<00:00, 24.76it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 72: 100%|██| 13371/13371 [09:10<00:00, 24.30it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 73: 100%|██| 13371/13371 [09:17<00:00, 23.97it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 74: 100%|██| 13371/13371 [09:02<00:00, 24.67it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 75: 100%|██| 13371/13371 [09:14<00:00, 24.11it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 76: 100%|██| 13371/13371 [09:01<00:00, 24.70it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 77: 100%|██| 13371/13371 [09:08<00:00, 24.37it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 78: 100%|██| 13371/13371 [09:15<00:00, 24.08it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 79: 100%|██| 13371/13371 [09:02<00:00, 24.66it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 80: 100%|██| 13371/13371 [09:09<00:00, 24.34it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 81: 100%|██| 13371/13371 [09:02<00:00, 24.64it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 82: 100%|██| 13371/13371 [09:17<00:00, 23.99it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 83: 100%|██| 13371/13371 [09:08<00:00, 24.40it/s, v_num=1488, train_loss=5.010, val_loss=5.010]\u001b[A\n",
      "Epoch 84: 100%|██| 13371/13371 [09:14<00:00, 24.09it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 85: 100%|██| 13371/13371 [09:13<00:00, 24.15it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 86: 100%|██| 13371/13371 [09:21<00:00, 23.81it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 87: 100%|██| 13371/13371 [09:27<00:00, 23.57it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 88: 100%|██| 13371/13371 [09:21<00:00, 23.81it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 89: 100%|██| 13371/13371 [09:24<00:00, 23.68it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 90: 100%|██| 13371/13371 [09:24<00:00, 23.68it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 91: 100%|██| 13371/13371 [09:21<00:00, 23.83it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 92: 100%|██| 13371/13371 [09:22<00:00, 23.77it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 93: 100%|██| 13371/13371 [09:04<00:00, 24.57it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 94: 100%|██| 13371/13371 [08:23<00:00, 26.57it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 95: 100%|██| 13371/13371 [07:36<00:00, 29.28it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 96: 100%|██| 13371/13371 [07:40<00:00, 29.01it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 97: 100%|██| 13371/13371 [07:38<00:00, 29.17it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 98: 100%|██| 13371/13371 [07:36<00:00, 29.30it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 99: 100%|██| 13371/13371 [07:33<00:00, 29.45it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A\n",
      "Epoch 99: 100%|██| 13371/13371 [07:44<00:00, 28.77it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██| 13371/13371 [07:44<00:00, 28.77it/s, v_num=1488, train_loss=5.010, val_loss=5.000]\n",
      "DONE SAVING PRETRAINED MODEL\n",
      "   | Name                                             | Type             | Params | Mode \n",
      "-----------------------------------------------------------------------------------------------\n",
      "0  | task_loss_fn                                     | MSELoss          | 0      | train\n",
      "1  | joint_loss_fn                                    | JointLoss        | 0      | train\n",
      "2  | joint_loss_fn.mse_loss                           | MSELoss          | 0      | train\n",
      "3  | joint_loss_fn.criterion                          | CrossEntropyLoss | 0      | train\n",
      "4  | model                                            | SubTab           | 207 K  | train\n",
      "5  | model._SubTab__auto_encoder                      | AutoEncoder      | 107 K  | train\n",
      "6  | model._SubTab__auto_encoder.encoder              | ShallowEncoder   | 8.2 K  | train\n",
      "7  | model._SubTab__auto_encoder.encoder.net          | Sequential       | 8.2 K  | train\n",
      "8  | model._SubTab__auto_encoder.encoder.net.0        | Linear           | 8.2 K  | train\n",
      "9  | model._SubTab__auto_encoder.decoder              | ShallowDecoder   | 18.5 K | train\n",
      "10 | model._SubTab__auto_encoder.decoder.net          | Linear           | 18.5 K | train\n",
      "11 | model._SubTab__auto_encoder.projection_net       | Sequential       | 80.4 K | train\n",
      "12 | model._SubTab__auto_encoder.projection_net.0     | Linear           | 40.2 K | train\n",
      "13 | model._SubTab__auto_encoder.projection_net.1     | LeakyReLU        | 0      | train\n",
      "14 | model._SubTab__auto_encoder.projection_net.2     | Linear           | 40.2 K | train\n",
      "15 | model.one_layer_prediction_head                  | Sequential       | 40.4 K | train\n",
      "16 | model.one_layer_prediction_head.head_linear_hid  | Linear           | 40.2 K | train\n",
      "17 | model.one_layer_prediction_head.head_activation  | ReLU             | 0      | train\n",
      "18 | model.one_layer_prediction_head.head_linear_out  | Linear           | 201    | train\n",
      "19 | model.two_layer_prediction_head                  | Sequential       | 60.4 K | train\n",
      "20 | model.two_layer_prediction_head.head_linear_hid1 | Linear           | 40.2 K | train\n",
      "21 | model.two_layer_prediction_head.head_activation1 | ReLU             | 0      | train\n",
      "22 | model.two_layer_prediction_head.head_linear_hid2 | Linear           | 20.1 K | train\n",
      "23 | model.two_layer_prediction_head.head_activation2 | ReLU             | 0      | train\n",
      "24 | model.two_layer_prediction_head.head_linear_out  | Linear           | 101    | train\n",
      "-----------------------------------------------------------------------------------------------\n",
      "207 K     Trainable params\n",
      "0         Non-trainable params\n",
      "207 K     Total params\n",
      "0.832     Total estimated model params size (MB)\n",
      "DONE PRETRAINING\n"
     ]
    }
   ],
   "source": [
    "s3l_training(pretrain=True, # if True First Phase training\n",
    "             use_pretrained_model=False, # if True Second Phase learning\n",
    "             pt_type='subtab', \n",
    "             pt_folder='FP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8d66f-43f4-4559-90b8-68a3a5bd8d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
