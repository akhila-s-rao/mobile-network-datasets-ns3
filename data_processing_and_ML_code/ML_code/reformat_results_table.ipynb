{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159f25a0-f014-46f6-bb97-1a11ac30501f",
   "metadata": {},
   "source": [
    "# Read the tables, we have 1 per model \n",
    "# Separate the first n line and the next n and so for each num of labeled samples \n",
    "# combine\n",
    "# write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6be940-e9c6-44fc-969d-1f8d7753dfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\hline\n",
      "\\multicolumn{6}{|c|}{\\rule{0pt}{2.5ex}Num. of labeled samples = 100\\rule[-1ex]{0pt}{2.5ex}}\\\\\n",
      "\\hline\n",
      "\\textbf{T 1} & 0.202 & -0.036 & -0.227 & 0.318 & 0.416 \\\\\n",
      "\\textbf{T 2} & 0.487 & 0.528 & 0.449 & 0.335 & 0.278 \\\\\n",
      "\\textbf{T 3} & 0.831 & 0.832 & 0.672 & -0.281 & -0.468 \\\\\n",
      "\\textbf{T 4} & 0.84 & 0.834 & 0.69 & -0.275 & -0.436 \\\\\n",
      "\\textbf{T 5} & 0.44 & 0.424 & 0.364 & 0.091 & 0.092 \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{|c|}{\\rule{0pt}{2.5ex}Num. of labeled samples = 250\\rule[-1ex]{0pt}{2.5ex}}\\\\\n",
      "\\hline\n",
      "\\textbf{T 1} & 0.412 & 0.129 & 0.15 & 0.402 & 0.612 \\\\\n",
      "\\textbf{T 2} & 0.601 & 0.652 & 0.596 & 0.446 & 0.628 \\\\\n",
      "\\textbf{T 3} & 0.907 & 0.888 & 0.852 & 0.472 & 0.034 \\\\\n",
      "\\textbf{T 4} & 0.879 & 0.912 & 0.847 & 0.407 & 0.016 \\\\\n",
      "\\textbf{T 5} & 0.759 & 0.654 & 0.636 & 0.255 & 0.443 \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{|c|}{\\rule{0pt}{2.5ex}Num. of labeled samples = 500\\rule[-1ex]{0pt}{2.5ex}}\\\\\n",
      "\\hline\n",
      "\\textbf{T 1} & 0.512 & 0.423 & 0.244 & 0.44 & 0.706 \\\\\n",
      "\\textbf{T 2} & 0.66 & 0.728 & 0.624 & 0.482 & 0.79 \\\\\n",
      "\\textbf{T 3} & 0.942 & 0.946 & 0.888 & 0.767 & 0.534 \\\\\n",
      "\\textbf{T 4} & 0.939 & 0.918 & 0.883 & 0.762 & 0.499 \\\\\n",
      "\\textbf{T 5} & 0.87 & 0.785 & 0.792 & 0.314 & 0.667 \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{|c|}{\\rule{0pt}{2.5ex}Num. of labeled samples = 1K\\rule[-1ex]{0pt}{2.5ex}}\\\\\n",
      "\\hline\n",
      "\\textbf{T 1} & 0.676 & 0.571 & 0.413 & 0.504 & 0.865 \\\\\n",
      "\\textbf{T 2} & 0.748 & 0.782 & 0.711 & 0.52 & 0.85 \\\\\n",
      "\\textbf{T 3} & 0.953 & 0.955 & 0.877 & 0.828 & 0.867 \\\\\n",
      "\\textbf{T 4} & 0.949 & 0.943 & 0.893 & 0.823 & 0.847 \\\\\n",
      "\\textbf{T 5} & 0.877 & 0.845 & 0.822 & 0.386 & 0.793 \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{|c|}{\\rule{0pt}{2.5ex}Num. of labeled samples = 10K\\rule[-1ex]{0pt}{2.5ex}}\\\\\n",
      "\\hline\n",
      "\\textbf{T 1} & 0.885 & 0.915 & 0.847 & 0.518 & 0.97 \\\\\n",
      "\\textbf{T 2} & 0.905 & 0.902 & 0.902 & 0.549 & 0.922 \\\\\n",
      "\\textbf{T 3} & 0.986 & 0.99 & 0.972 & 0.839 & 0.978 \\\\\n",
      "\\textbf{T 4} & 0.98 & 0.98 & 0.97 & 0.841 & 0.969 \\\\\n",
      "\\textbf{T 5} & 0.931 & 0.95 & 0.91 & 0.466 & 0.95 \\\\\n",
      "\\hline\n",
      "\\multicolumn{6}{|c|}{\\rule{0pt}{2.5ex}Num. of labeled samples = 20K\\rule[-1ex]{0pt}{2.5ex}}\\\\\n",
      "\\hline\n",
      "\\textbf{T 1} & 0.946 & 0.944 & 0.923 & 0.583 & 0.977 \\\\\n",
      "\\textbf{T 2} & 0.913 & 0.895 & 0.918 & 0.591 & 0.936 \\\\\n",
      "\\textbf{T 3} & 0.987 & 0.991 & 0.976 & 0.846 & 0.978 \\\\\n",
      "\\textbf{T 4} & 0.98 & 0.981 & 0.963 & 0.853 & 0.974 \\\\\n",
      "\\textbf{T 5} & 0.955 & 0.959 & 0.908 & 0.528 & 0.95 \\\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Location of the results csv files\n",
    "results_prefix_str = 'FP2_SP_sameWind_1layer_unfrozen/s3l_'\n",
    "#results_prefix_str = 'XGB/s3l_'\n",
    "#results_prefix_str = 'baseline_sameWind_1layer/s3l_'\n",
    "\n",
    "#model_list = ['xgb', 'dae_xgb', 'scarf_xgb', 'vime_xgb' ,'subtab_xgb', 'switchtab_xgb']\n",
    "#model_list = ['3layer_mlp', '4layer_mlp']\n",
    "model_list = ['dae', 'scarf', 'vime', 'subtab', 'switchtab']\n",
    "#model_list = ['1layer_mse_mlp', '1layer_l1loss_mlp','1layer_smoothl1loss_mlp','1layer_mape_mlp']\n",
    "\n",
    "#num_samples_list = ['100', '1K', '10K', '20K']\n",
    "num_samples_list = ['100', '250', '500', '1K', '10K', '20K']\n",
    "\n",
    "#tasks = ['VR fragment thput.', 'VR burst thput.', 'VR fragment latency', 'VR burst latency', \n",
    "#         'UL probe latency', \n",
    "#         'DL probe latency'\n",
    "#        ]\n",
    "tasks = ['T 1', 'T 2', 'T 3', 'T 4', 'T 5']\n",
    "task_str = [\"\\\\textbf{T 1} & \", \n",
    "                \"\\\\textbf{T 2} & \", \n",
    "                \"\\\\textbf{T 3} & \", \n",
    "                \"\\\\textbf{T 4} & \", \n",
    "                \"\\\\textbf{T 5} & \"\n",
    "               ]\n",
    "\n",
    "results = {}\n",
    "# Read all the results\n",
    "for model in model_list:\n",
    "    results_ff = pd.read_csv(results_prefix_str+model+'_test_results.csv', delimiter=\",\", header=None)\n",
    "    results[model] = {}\n",
    "    i_start = 0\n",
    "    for samp in num_samples_list:\n",
    "        results[model][samp] = results_ff.iloc[i_start:i_start+5]\n",
    "        i_start = i_start + 5\n",
    "    \n",
    "# For each error metric type \n",
    "# for each num of samples \n",
    "for num_samp in num_samples_list:\n",
    "    print('\\hline')\n",
    "    print(r\"\\multicolumn{\"+str(len(model_list)+1)+r\"}{|c|}{\\rule{0pt}{2.5ex}Num. of labeled samples = \"+num_samp+r\"\\rule[-1ex]{0pt}{2.5ex}}\\\\\")\n",
    "    print('\\hline')\n",
    "    #print('Num of samples: ', num_samp)\n",
    "    # create 3 err metric dataframnes \n",
    "    err_r2 = pd.DataFrame(index=tasks, columns=model_list)\n",
    "    err_mape = pd.DataFrame(index=tasks, columns=model_list)\n",
    "    err_mae = pd.DataFrame(index=tasks, columns=model_list)\n",
    "    err_r2 = err_r2.astype(float)\n",
    "    err_mape = err_mape.astype(float)\n",
    "    err_mae = err_mae.astype(float)\n",
    "    \n",
    "    for model in model_list:\n",
    "        # add one column at a time \n",
    "        err_mae.loc[:, model] = results[model][num_samp].iloc[:,1]\n",
    "        err_mape.loc[:, model] = results[model][num_samp].iloc[:,2]\n",
    "        err_r2.loc[:, model] = results[model][num_samp].iloc[:,3]\n",
    "        #print('model:', model)\n",
    "        #print(results[model][num_samp])\n",
    "    \n",
    "    \n",
    "    #print(err_mae)\n",
    "    #print(err_mape)\n",
    "    #print(err_r2)\n",
    "    err_r2 = err_r2.round(3)\n",
    "    err_mae = err_mae.round(3)\n",
    "    err_mape = err_mape.round(3)\n",
    "\n",
    "    # CHECK HERE !!!!\n",
    "    error_metric_to_print = err_r2\n",
    "\n",
    "    # Convert DataFrame to a LaTeX-friendly format\n",
    "    latex_table = error_metric_to_print.apply(lambda row: ' & '.join(row.astype(str)), axis=1)\n",
    "    latex_table = task_str + latex_table + ' \\\\\\\\'\n",
    "    \n",
    "    # Join the rows with newline characters\n",
    "    latex_table_str = '\\n'.join(latex_table)\n",
    "    \n",
    "    print(latex_table_str)\n",
    "    \n",
    "# Print with & as the delimiter to make it each to import into latex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c7c84-2b79-46fe-ae76-d8e16a73bfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
