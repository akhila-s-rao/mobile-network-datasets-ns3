{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed58de6-5ac0-4bbb-95e7-c77e64dfaf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload\n",
    "#%reset\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# DEBUG MODE\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "    \n",
    "from s3l_training import s3l_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb320c-c17f-40dd-8264-6dcbd0933f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random seed:  561\n",
      "GPU is available.\n",
      "1\n",
      "True\n",
      "12.1\n",
      "Concatenating runs:  range(1, 11)\n",
      "Time to read csv file for run:  3.355344295501709\n",
      "Loaded run 1\n",
      "Time to read csv file for run:  3.1120033264160156\n",
      "Loaded run 2\n",
      "Time to read csv file for run:  3.1676371097564697\n",
      "Loaded run 3\n",
      "Time to read csv file for run:  3.091982126235962\n",
      "Loaded run 4\n",
      "Time to read csv file for run:  3.0651609897613525\n",
      "Loaded run 5\n",
      "Time to read csv file for run:  2.8629770278930664\n",
      "Loaded run 6\n",
      "Time to read csv file for run:  2.993557929992676\n",
      "Loaded run 7\n",
      "Time to read csv file for run:  3.0963659286499023\n",
      "Loaded run 8\n",
      "Time to read csv file for run:  3.1366958618164062\n",
      "Loaded run 9\n",
      "Time to read csv file for run:  3.364623546600342\n",
      "Loaded run 10\n",
      "pretrain_data, before removing rows that dont have traffic  (1799100, 102)\n",
      "pretrain_data, after removing rows that dont have traffic  (1799100, 102)\n",
      "X_pretrain  (1796746, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETERS:  {'loss_fn': 'MSELoss', 'metric': 'r2_score', 'hidden_dim': 200, 'max_epochs': 100, 'batch_size': 128, 'optim_hparams': {'lr': 0.0001, 'weight_decay': 5e-05}, 'encoder_depth': 4, 'head_depth': 2, 'dropout_rate': 0.1, 'noise_type': 'Swap', 'noise_ratio': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type    | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | task_loss_fn             | MSELoss | 0      | train\n",
      "1 | mask_loss_fn             | BCELoss | 0      | train\n",
      "2 | categorical_feature_loss | BCELoss | 0      | train\n",
      "3 | continuous_feature_loss  | MSELoss | 0      | train\n",
      "4 | model                    | DAE     | 295 K  | train\n",
      "-------------------------------------------------------------\n",
      "295 K     Trainable params\n",
      "0         Non-trainable params\n",
      "295 K     Total params\n",
      "1.183     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh rate:  10\n",
      "Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████| 12704/12704 [02:21<00:00, 89.78it/s]\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 88.03it/s, train_loss=1.040, val_loss=0.855]\u001b[A\n",
      "Epoch 2: 100%|██████████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.67it/s, train_loss=0.906, val_loss=0.827]\u001b[A\n",
      "Epoch 3: 100%|██████████████████████████████████████████████████| 12704/12704 [02:22<00:00, 88.96it/s, train_loss=0.884, val_loss=0.815]    \u001b[A\n",
      "Epoch 4: 100%|██████████████████████████████████████████████████| 12704/12704 [02:26<00:00, 86.95it/s, train_loss=0.870, val_loss=0.801]\u001b[A\n",
      "Epoch 5: 100%|██████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.57it/s, train_loss=0.861, val_loss=0.800]\u001b[A\n",
      "Epoch 6: 100%|██████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.45it/s, train_loss=0.852, val_loss=0.788]\u001b[A\n",
      "Epoch 7: 100%|██████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.34it/s, train_loss=0.847, val_loss=0.786]\u001b[A\n",
      "Epoch 8: 100%|██████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 88.17it/s, train_loss=0.840, val_loss=0.777]\u001b[A\n",
      "Epoch 9: 100%|██████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.89it/s, train_loss=0.833, val_loss=0.779]\u001b[A\n",
      "Epoch 10: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.74it/s, train_loss=0.828, val_loss=0.768]\u001b[A\n",
      "Epoch 11: 100%|█████████████████████████████████████████████████| 12704/12704 [02:25<00:00, 87.45it/s, train_loss=0.823, val_loss=0.761]\u001b[A\n",
      "Epoch 12: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.73it/s, train_loss=0.818, val_loss=0.759]\u001b[A\n",
      "Epoch 13: 100%|█████████████████████████████████████████████████| 12704/12704 [02:25<00:00, 87.19it/s, train_loss=0.813, val_loss=0.749]\u001b[A\n",
      "Epoch 14: 100%|█████████████████████████████████████████████████| 12704/12704 [02:25<00:00, 87.42it/s, train_loss=0.809, val_loss=0.751]\u001b[A\n",
      "Epoch 15: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.65it/s, train_loss=0.804, val_loss=0.741]\u001b[A\n",
      "Epoch 16: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.99it/s, train_loss=0.801, val_loss=0.739]\u001b[A\n",
      "Epoch 17: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.63it/s, train_loss=0.796, val_loss=0.736]\u001b[A\n",
      "Epoch 18: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.70it/s, train_loss=0.792, val_loss=0.734]\u001b[A\n",
      "Epoch 19: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.43it/s, train_loss=0.788, val_loss=0.733]\u001b[A\n",
      "Epoch 20: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.86it/s, train_loss=0.784, val_loss=0.719]\u001b[A\n",
      "Epoch 21: 100%|█████████████████████████████████████████████████| 12704/12704 [02:26<00:00, 86.97it/s, train_loss=0.781, val_loss=0.717]\u001b[A\n",
      "Epoch 22: 100%|█████████████████████████████████████████████████| 12704/12704 [02:26<00:00, 86.66it/s, train_loss=0.777, val_loss=0.715]\u001b[A\n",
      "Epoch 23: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.64it/s, train_loss=0.774, val_loss=0.710]\u001b[A\n",
      "Epoch 24: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.71it/s, train_loss=0.771, val_loss=0.706]\u001b[A\n",
      "Epoch 25: 100%|█████████████████████████████████████████████████| 12704/12704 [02:27<00:00, 86.36it/s, train_loss=0.768, val_loss=0.705]\u001b[A\n",
      "Epoch 26: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.72it/s, train_loss=0.765, val_loss=0.703]\u001b[A\n",
      "Epoch 27: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.41it/s, train_loss=0.762, val_loss=0.704]\u001b[A\n",
      "Epoch 28: 100%|█████████████████████████████████████████████████| 12704/12704 [02:26<00:00, 87.00it/s, train_loss=0.759, val_loss=0.693]\u001b[A\n",
      "Epoch 29: 100%|█████████████████████████████████████████████████| 12704/12704 [02:22<00:00, 89.01it/s, train_loss=0.756, val_loss=0.694]\u001b[A\n",
      "Epoch 30: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 88.21it/s, train_loss=0.754, val_loss=0.685]\u001b[A\n",
      "Epoch 31: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.85it/s, train_loss=0.750, val_loss=0.691]\u001b[A\n",
      "Epoch 32: 100%|█████████████████████████████████████████████████| 12704/12704 [02:25<00:00, 87.22it/s, train_loss=0.749, val_loss=0.686]\u001b[A\n",
      "Epoch 33: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.25it/s, train_loss=0.745, val_loss=0.680]\u001b[A\n",
      "Epoch 34: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 88.03it/s, train_loss=0.743, val_loss=0.680]\u001b[A\n",
      "Epoch 35: 100%|█████████████████████████████████████████████████| 12704/12704 [02:22<00:00, 89.20it/s, train_loss=0.742, val_loss=0.677]\u001b[A\n",
      "Epoch 36: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.41it/s, train_loss=0.738, val_loss=0.673]\u001b[A\n",
      "Epoch 37: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.82it/s, train_loss=0.737, val_loss=0.675]\u001b[A\n",
      "Epoch 38: 100%|█████████████████████████████████████████████████| 12704/12704 [02:22<00:00, 88.86it/s, train_loss=0.736, val_loss=0.673]\u001b[A\n",
      "Epoch 39: 100%|█████████████████████████████████████████████████| 12704/12704 [02:26<00:00, 86.96it/s, train_loss=0.733, val_loss=0.667]\u001b[A\n",
      "Epoch 40: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.45it/s, train_loss=0.731, val_loss=0.672]\u001b[A\n",
      "Epoch 41: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.30it/s, train_loss=0.730, val_loss=0.666]\u001b[A\n",
      "Epoch 42: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.68it/s, train_loss=0.730, val_loss=0.663]\u001b[A\n",
      "Epoch 43: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.42it/s, train_loss=0.726, val_loss=0.664]\u001b[A\n",
      "Epoch 44: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.44it/s, train_loss=0.724, val_loss=0.660]\u001b[A\n",
      "Epoch 45: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 88.19it/s, train_loss=0.725, val_loss=0.667]\u001b[A\n",
      "Epoch 46: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.87it/s, train_loss=0.722, val_loss=0.667]\u001b[A\n",
      "Epoch 47: 100%|█████████████████████████████████████████████████| 12704/12704 [02:25<00:00, 87.39it/s, train_loss=0.721, val_loss=0.659]\u001b[A\n",
      "Epoch 48: 100%|█████████████████████████████████████████████████| 12704/12704 [02:22<00:00, 88.84it/s, train_loss=0.721, val_loss=0.654]\u001b[A\n",
      "Epoch 49: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 88.08it/s, train_loss=0.720, val_loss=0.660]\u001b[A\n",
      "Epoch 50: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 87.97it/s, train_loss=0.717, val_loss=0.651]\u001b[A\n",
      "Epoch 51: 100%|█████████████████████████████████████████████████| 12704/12704 [02:24<00:00, 88.13it/s, train_loss=0.717, val_loss=0.651]\u001b[A\n",
      "Epoch 52: 100%|█████████████████████████████████████████████████| 12704/12704 [02:25<00:00, 87.39it/s, train_loss=0.717, val_loss=0.649]\u001b[A\n",
      "Epoch 53: 100%|█████████████████████████████████████████████████| 12704/12704 [02:23<00:00, 88.62it/s, train_loss=0.714, val_loss=0.649]\u001b[A\n",
      "Epoch 54: 100%|█████████████████████████████████████████████████| 12704/12704 [02:22<00:00, 88.97it/s, train_loss=0.713, val_loss=0.646]\u001b[A\n",
      "Epoch 55:  21%|██████████▌                                       | 2690/12704 [00:31<01:55, 86.41it/s, train_loss=0.712, val_loss=0.651]\u001b[A"
     ]
    }
   ],
   "source": [
    "s3l_training(pretrain=True, # if True First Phase training\n",
    "             use_pretrained_model=False, # if True Second Phase learning\n",
    "             pt_type='subtab', \n",
    "             pt_folder='FP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7160f9-4db4-4688-9556-ba884a04eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
