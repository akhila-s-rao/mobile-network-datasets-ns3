Pretrained model used in from iteration 2

    s3l_hyp_ssl_dae={
        'metric': "mean_absolute_percentage_error", #
        'hidden_dim': 200, #
        'max_epochs': 100, #
        'batch_size': 128, #
        
        'encoder_depth': 4, #  
        'head_depth': 2, #
        'dropout_rate': 0.1, #
        
        'noise_type': "Swap", #
        'noise_ratio': 0.3, #
    }
    
    s3l_hyp_ssl_vime={
        'metric': "mean_absolute_percentage_error", #
        'hidden_dim': 200, #
        'max_epochs': 100, #
        'batch_size': 128, #

        # NO ENCODER DEPTH 
        # NO HEAD DEPTH
        # NO DROPOUT
        
        'p_m': 0.3, # Corruption probability for self-supervised learning
        
        'alpha1': 2.0, # Hyper-parameter to control the weights of feature and mask losses
        'alpha2': 2.0, # Hyper-parameter to control the weights of feature and mask losses
        'K': 3, # Number of augmented samples
        'beta': 1.0 # Hyperparameter to control supervised and unsupervised losses
    }
    
    s3l_hyp_ssl_scarf={
        'metric': "mean_absolute_percentage_error",
        'hidden_dim': 200,
        'max_epochs': 100,
        'batch_size': 128,
        
        'encoder_depth': 4,
        'head_depth': 2,
        'dropout_rate': 0.1, #
        
        'corruption_rate': 0.3
    }
    
    s3l_hyp_ssl_subtab={
        'metric': "mean_absolute_percentage_error",
        'hidden_dim': 200,
        'max_epochs': 100,
        'batch_size': 128,
        
        'encoder_depth': 4,
        'head_depth': 2,
        # NO DROPOUT

        'noise_type': "Swap",
        'noise_level': 0.3,
        
        'tau': 1.0,
        'use_cosine_similarity': True,
        'use_contrastive': True,
        'use_distance': True,
        'n_subsets': 4,
        'overlap_ratio': 0.75,
        'mask_ratio': 0.1
        
        
    }
    
    s3l_hyp_ssl_switchtab={
        'metric': "mean_absolute_percentage_error",
        'hidden_dim': 200,
        'max_epochs': 100,
        'batch_size': 128,
        
        'encoder_depth': 4,
        # NO HEAD DEPTH
        'dropout_rate': 0.1, #
        
        'n_head': 2,
        'u_label': -1
    }







Seconf phase training 
1 hidden layer on prediction head the sanme size as the hidden layer in the pretrained nmodel = 200
Unfrozen weights 

    s3l_hyp_pred_head={
        'batch_size': 32,
        'max_epochs': 30,
        'patience': 5,
        'loss':{'reg':'MSELoss',
                'clas':'CrossEntropyLoss'},
        'metrics':{'reg':['MeanAbsolutePercentageError'],
                   'clas':['Recall']},#'F1Score' does not work needs a different dimension 
    }

Next step prediction 