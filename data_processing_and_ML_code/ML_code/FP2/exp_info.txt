FP2

These are models trained after I equalized the noise corruption ratio, dropout. I also equalized the prediction head layers, which while actually used in SP, need to already be in the model Class file used for training FP. 

The encoders still have different depths. VIME has 1 layer encoder. And I don't know what is hapenning with Subtab

DAE and VIME were retrained after the bug fix. So was awitchtab even though the bug does not affect it, since it did not complete training last time.
scarf, switchtab are what we had from before since they did not have the bug. 


Hyperparameters 

    s3l_hyp_ssl_dae={
        'metric': "mean_absolute_percentage_error", #
        'hidden_dim': 200, #
        'max_epochs': 100, #
        'batch_size': 128, #
        
        'encoder_depth': 4, #  
        'head_depth': 2, #
        'dropout_rate': 0.1, #
        
        'noise_type': "Swap", #
        'noise_ratio': 0.3 #
    }
    
    s3l_hyp_ssl_vime={
        'metric': "mean_absolute_percentage_error", #
        'hidden_dim': 200, #
        'max_epochs': 100, #
        'batch_size': 128, #

        # NO ENCODER DEPTH 
        # NO HEAD DEPTH
        # NO DROPOUT
        
        'p_m': 0.3, # Corruption probability for self-supervised learning
        
        'alpha1': 2.0, # Hyper-parameter to control the weights of feature and mask losses
        'alpha2': 2.0, # Hyper-parameter to control the weights of feature and mask losses
        'K': 3, # Number of augmented samples
        'beta': 1.0 # Hyperparameter to control supervised and unsupervised losses
    }
    
    s3l_hyp_ssl_scarf={
        'metric': "mean_absolute_percentage_error",
        'hidden_dim': 200,
        'max_epochs': 100,
        'batch_size': 128,
        
        'encoder_depth': 4,
        'head_depth': 2,
        'dropout_rate': 0.1, #
        
        'corruption_rate': 0.3
    }
    
    s3l_hyp_ssl_subtab={
        'metric': "mean_absolute_percentage_error",
        'hidden_dim': 200,
        'max_epochs': 100,
        'batch_size': 128,
        
        'encoder_depth': 4,
        'head_depth': 2,
        # NO DROPOUT

        'noise_type': "Swap",
        'noise_level': 0.3,
        
        'tau': 1.0,
        'use_cosine_similarity': True,
        'use_contrastive': True,
        'use_distance': True,
        'n_subsets': 4,
        'overlap_ratio': 0.75,
        'mask_ratio': 0.1
        
        
    }
    
    s3l_hyp_ssl_switchtab={
        'metric': "mean_absolute_percentage_error",
        'hidden_dim': 200,
        'max_epochs': 100,
        'batch_size': 128,
        
        'encoder_depth': 4,
        # NO HEAD DEPTH
        'corruption_rate': 0.3,
        'dropout_rate': 0.1, #
        
        'n_head': 2,
        'u_label': -1
    }

