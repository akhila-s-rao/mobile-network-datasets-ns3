{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed58de6-5ac0-4bbb-95e7-c77e64dfaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "#%reset\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# DEBUG MODE\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "    \n",
    "from s3l_training import s3l_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26eb320c-c17f-40dd-8264-6dcbd0933f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random seed:  561\n",
      "GPU is available.\n",
      "1\n",
      "True\n",
      "12.1\n",
      "Concatenating runs:  range(1, 11)\n",
      "Time to read csv file for run:  3.6430084705352783\n",
      "Loaded run 1\n",
      "Time to read csv file for run:  3.691406726837158\n",
      "Loaded run 2\n",
      "Time to read csv file for run:  3.532330274581909\n",
      "Loaded run 3\n",
      "Time to read csv file for run:  3.4480292797088623\n",
      "Loaded run 4\n",
      "Time to read csv file for run:  3.460449695587158\n",
      "Loaded run 5\n",
      "Time to read csv file for run:  3.461461067199707\n",
      "Loaded run 6\n",
      "Time to read csv file for run:  3.1470494270324707\n",
      "Loaded run 7\n",
      "Time to read csv file for run:  3.148127317428589\n",
      "Loaded run 8\n",
      "Time to read csv file for run:  3.209243059158325\n",
      "Loaded run 9\n",
      "Time to read csv file for run:  3.123150110244751\n",
      "Loaded run 10\n",
      "cell_conn_type\n",
      "[0 1]\n",
      "categorical_cols:  ['cell_conn_type']\n",
      "(1796746, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1621562, 92)\n",
      "(89838, 92)\n",
      "(85346, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh rate:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                        | Type    | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | task_loss_fn                | MSELoss | 0      | train\n",
      "1 | mask_loss_fn                | BCELoss | 0      | train\n",
      "2 | categorical_feature_loss_fn | BCELoss | 0      | train\n",
      "3 | continuous_feature_loss_fn  | MSELoss | 0      | train\n",
      "4 | consistency_loss_fn         | MSELoss | 0      | train\n",
      "5 | model                       | VIME    | 278 K  | train\n",
      "----------------------------------------------------------------\n",
      "278 K     Trainable params\n",
      "0         Non-trainable params\n",
      "278 K     Total params\n",
      "1.113     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.25it/s, v_num=1278]\n",
      "Epoch 1: 100%|██████████████████████████████████████████| 13371/13371 [03:45<00:00, 59.28it/s, v_num=1278, train_loss=3.050, val_loss=2.940]\u001b[A\n",
      "Epoch 2: 100%|██████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.32it/s, v_num=1278, train_loss=2.980, val_loss=2.920]\u001b[A\n",
      "Epoch 3: 100%|██████████████████████████████████████████| 13371/13371 [03:37<00:00, 61.55it/s, v_num=1278, train_loss=2.960, val_loss=2.910]\u001b[A\n",
      "Epoch 4: 100%|██████████████████████████████████████████| 13371/13371 [03:30<00:00, 63.65it/s, v_num=1278, train_loss=2.960, val_loss=2.900]\u001b[A\n",
      "Epoch 5: 100%|██████████████████████████████████████████| 13371/13371 [03:44<00:00, 59.48it/s, v_num=1278, train_loss=2.950, val_loss=2.890]\u001b[A\n",
      "Epoch 6: 100%|██████████████████████████████████████████| 13371/13371 [03:42<00:00, 60.08it/s, v_num=1278, train_loss=2.940, val_loss=2.890]\u001b[A\n",
      "Epoch 7: 100%|██████████████████████████████████████████| 13371/13371 [03:35<00:00, 61.95it/s, v_num=1278, train_loss=2.940, val_loss=2.880]\u001b[A\n",
      "Epoch 8: 100%|██████████████████████████████████████████| 13371/13371 [03:29<00:00, 63.86it/s, v_num=1278, train_loss=2.930, val_loss=2.880]\u001b[A\n",
      "Epoch 9: 100%|██████████████████████████████████████████| 13371/13371 [03:46<00:00, 59.11it/s, v_num=1278, train_loss=2.930, val_loss=2.870]\u001b[A\n",
      "Epoch 10: 100%|█████████████████████████████████████████| 13371/13371 [03:46<00:00, 58.97it/s, v_num=1278, train_loss=2.920, val_loss=2.870]\u001b[A\n",
      "Epoch 11: 100%|█████████████████████████████████████████| 13371/13371 [03:43<00:00, 59.93it/s, v_num=1278, train_loss=2.920, val_loss=2.860]\u001b[A\n",
      "Epoch 12: 100%|█████████████████████████████████████████| 13371/13371 [03:37<00:00, 61.50it/s, v_num=1278, train_loss=2.920, val_loss=2.860]\u001b[A\n",
      "Epoch 13: 100%|█████████████████████████████████████████| 13371/13371 [03:33<00:00, 62.49it/s, v_num=1278, train_loss=2.910, val_loss=2.850]\u001b[A\n",
      "Epoch 14: 100%|█████████████████████████████████████████| 13371/13371 [03:51<00:00, 57.83it/s, v_num=1278, train_loss=2.910, val_loss=2.850]\u001b[A\n",
      "Epoch 15: 100%|█████████████████████████████████████████| 13371/13371 [03:47<00:00, 58.73it/s, v_num=1278, train_loss=2.910, val_loss=2.840]\u001b[A\n",
      "Epoch 16: 100%|█████████████████████████████████████████| 13371/13371 [03:37<00:00, 61.40it/s, v_num=1278, train_loss=2.900, val_loss=2.840]\u001b[A\n",
      "Epoch 17: 100%|█████████████████████████████████████████| 13371/13371 [03:29<00:00, 63.92it/s, v_num=1278, train_loss=2.900, val_loss=2.830]\u001b[A\n",
      "Epoch 18: 100%|█████████████████████████████████████████| 13371/13371 [03:44<00:00, 59.58it/s, v_num=1278, train_loss=2.900, val_loss=2.830]\u001b[A\n",
      "Epoch 19: 100%|█████████████████████████████████████████| 13371/13371 [03:47<00:00, 58.65it/s, v_num=1278, train_loss=2.890, val_loss=2.830]\u001b[A\n",
      "Epoch 20: 100%|█████████████████████████████████████████| 13371/13371 [03:45<00:00, 59.31it/s, v_num=1278, train_loss=2.890, val_loss=2.820]\u001b[A\n",
      "Epoch 21: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.08it/s, v_num=1278, train_loss=2.890, val_loss=2.820]\u001b[A\n",
      "Epoch 22: 100%|█████████████████████████████████████████| 13371/13371 [03:31<00:00, 63.34it/s, v_num=1278, train_loss=2.880, val_loss=2.820]\u001b[A\n",
      "Epoch 23: 100%|█████████████████████████████████████████| 13371/13371 [03:41<00:00, 60.28it/s, v_num=1278, train_loss=2.880, val_loss=2.810]\u001b[A\n",
      "Epoch 24: 100%|█████████████████████████████████████████| 13371/13371 [03:43<00:00, 59.95it/s, v_num=1278, train_loss=2.880, val_loss=2.810]\u001b[A\n",
      "Epoch 25: 100%|█████████████████████████████████████████| 13371/13371 [03:42<00:00, 60.03it/s, v_num=1278, train_loss=2.880, val_loss=2.810]\u001b[A\n",
      "Epoch 26: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.22it/s, v_num=1278, train_loss=2.880, val_loss=2.810]\u001b[A\n",
      "Epoch 27: 100%|█████████████████████████████████████████| 13371/13371 [03:36<00:00, 61.73it/s, v_num=1278, train_loss=2.870, val_loss=2.800]\u001b[A\n",
      "Epoch 28: 100%|█████████████████████████████████████████| 13371/13371 [03:31<00:00, 63.18it/s, v_num=1278, train_loss=2.870, val_loss=2.800]\u001b[A\n",
      "Epoch 29: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.27it/s, v_num=1278, train_loss=2.870, val_loss=2.800]\u001b[A\n",
      "Epoch 30: 100%|█████████████████████████████████████████| 13371/13371 [03:43<00:00, 59.78it/s, v_num=1278, train_loss=2.870, val_loss=2.800]\u001b[A\n",
      "Epoch 31: 100%|█████████████████████████████████████████| 13371/13371 [03:41<00:00, 60.30it/s, v_num=1278, train_loss=2.870, val_loss=2.800]\u001b[A\n",
      "Epoch 32: 100%|█████████████████████████████████████████| 13371/13371 [03:41<00:00, 60.39it/s, v_num=1278, train_loss=2.870, val_loss=2.790]\u001b[A\n",
      "Epoch 33: 100%|█████████████████████████████████████████| 13371/13371 [03:39<00:00, 61.05it/s, v_num=1278, train_loss=2.860, val_loss=2.790]\u001b[A\n",
      "Epoch 34: 100%|█████████████████████████████████████████| 13371/13371 [03:35<00:00, 62.14it/s, v_num=1278, train_loss=2.860, val_loss=2.790]\u001b[A\n",
      "Epoch 35: 100%|█████████████████████████████████████████| 13371/13371 [03:30<00:00, 63.45it/s, v_num=1278, train_loss=2.860, val_loss=2.790]\u001b[A\n",
      "Epoch 36: 100%|█████████████████████████████████████████| 13371/13371 [03:42<00:00, 60.21it/s, v_num=1278, train_loss=2.860, val_loss=2.790]\u001b[A\n",
      "Epoch 37: 100%|█████████████████████████████████████████| 13371/13371 [03:40<00:00, 60.50it/s, v_num=1278, train_loss=2.860, val_loss=2.790]\u001b[A\n",
      "Epoch 38: 100%|█████████████████████████████████████████| 13371/13371 [03:43<00:00, 59.77it/s, v_num=1278, train_loss=2.860, val_loss=2.790]\u001b[A\n",
      "Epoch 39: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.28it/s, v_num=1278, train_loss=2.860, val_loss=2.790]\u001b[A\n",
      "Epoch 40: 100%|█████████████████████████████████████████| 13371/13371 [03:39<00:00, 60.84it/s, v_num=1278, train_loss=2.860, val_loss=2.780]\u001b[A\n",
      "Epoch 41: 100%|█████████████████████████████████████████| 13371/13371 [03:33<00:00, 62.62it/s, v_num=1278, train_loss=2.860, val_loss=2.780]\u001b[A\n",
      "Epoch 42: 100%|█████████████████████████████████████████| 13371/13371 [03:32<00:00, 62.81it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 43: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.10it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 44: 100%|█████████████████████████████████████████| 13371/13371 [03:40<00:00, 60.69it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 45: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.19it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 46: 100%|█████████████████████████████████████████| 13371/13371 [03:41<00:00, 60.47it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 47: 100%|█████████████████████████████████████████| 13371/13371 [03:36<00:00, 61.89it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 48: 100%|█████████████████████████████████████████| 13371/13371 [03:37<00:00, 61.52it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 49: 100%|█████████████████████████████████████████| 13371/13371 [03:34<00:00, 62.41it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 50: 100%|█████████████████████████████████████████| 13371/13371 [03:35<00:00, 62.08it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 51: 100%|█████████████████████████████████████████| 13371/13371 [03:34<00:00, 62.42it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 52: 100%|█████████████████████████████████████████| 13371/13371 [03:41<00:00, 60.47it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 53: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.13it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 54: 100%|█████████████████████████████████████████| 13371/13371 [03:41<00:00, 60.35it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 55: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.13it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 56: 100%|█████████████████████████████████████████| 13371/13371 [03:35<00:00, 61.93it/s, v_num=1278, train_loss=2.850, val_loss=2.780]\u001b[A\n",
      "Epoch 57: 100%|█████████████████████████████████████████| 13371/13371 [03:39<00:00, 60.99it/s, v_num=1278, train_loss=2.850, val_loss=2.770]\u001b[A\n",
      "Epoch 58: 100%|█████████████████████████████████████████| 13371/13371 [03:28<00:00, 64.25it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 59: 100%|█████████████████████████████████████████| 13371/13371 [03:40<00:00, 60.77it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 60: 100%|█████████████████████████████████████████| 13371/13371 [03:34<00:00, 62.24it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 61: 100%|█████████████████████████████████████████| 13371/13371 [03:40<00:00, 60.74it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 62: 100%|█████████████████████████████████████████| 13371/13371 [03:40<00:00, 60.73it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 63: 100%|█████████████████████████████████████████| 13371/13371 [03:39<00:00, 60.87it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 64: 100%|█████████████████████████████████████████| 13371/13371 [03:36<00:00, 61.79it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 65: 100%|█████████████████████████████████████████| 13371/13371 [03:38<00:00, 61.26it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 66: 100%|█████████████████████████████████████████| 13371/13371 [03:33<00:00, 62.64it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 67: 100%|█████████████████████████████████████████| 13371/13371 [03:14<00:00, 68.82it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 68: 100%|█████████████████████████████████████████| 13371/13371 [03:18<00:00, 67.35it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 69: 100%|█████████████████████████████████████████| 13371/13371 [03:04<00:00, 72.29it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 70: 100%|█████████████████████████████████████████| 13371/13371 [03:06<00:00, 71.72it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 71: 100%|█████████████████████████████████████████| 13371/13371 [03:04<00:00, 72.59it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 72: 100%|█████████████████████████████████████████| 13371/13371 [03:04<00:00, 72.40it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 73: 100%|█████████████████████████████████████████| 13371/13371 [03:04<00:00, 72.40it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 74: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.88it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 75: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.91it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 76: 100%|█████████████████████████████████████████| 13371/13371 [03:06<00:00, 71.67it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 77: 100%|█████████████████████████████████████████| 13371/13371 [03:04<00:00, 72.57it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 78: 100%|█████████████████████████████████████████| 13371/13371 [03:02<00:00, 73.22it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 79: 100%|█████████████████████████████████████████| 13371/13371 [03:08<00:00, 70.87it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 80: 100%|█████████████████████████████████████████| 13371/13371 [03:06<00:00, 71.57it/s, v_num=1278, train_loss=2.840, val_loss=2.770]\u001b[A\n",
      "Epoch 81: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.93it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 82: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.68it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 83: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 73.00it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 84: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 73.04it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 85: 100%|█████████████████████████████████████████| 13371/13371 [02:58<00:00, 74.99it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 86: 100%|█████████████████████████████████████████| 13371/13371 [02:59<00:00, 74.50it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 87: 100%|█████████████████████████████████████████| 13371/13371 [03:01<00:00, 73.77it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 88: 100%|█████████████████████████████████████████| 13371/13371 [03:04<00:00, 72.59it/s, v_num=1278, train_loss=2.840, val_loss=2.760]\u001b[A\n",
      "Epoch 89: 100%|█████████████████████████████████████████| 13371/13371 [03:00<00:00, 74.10it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 90: 100%|█████████████████████████████████████████| 13371/13371 [03:04<00:00, 72.66it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 91: 100%|█████████████████████████████████████████| 13371/13371 [03:06<00:00, 71.77it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 92: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.76it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 93: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.92it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 94: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.81it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 95: 100%|█████████████████████████████████████████| 13371/13371 [03:06<00:00, 71.64it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 96: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.84it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 97: 100%|█████████████████████████████████████████| 13371/13371 [03:02<00:00, 73.37it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 98: 100%|█████████████████████████████████████████| 13371/13371 [03:03<00:00, 72.87it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 99: 100%|█████████████████████████████████████████| 13371/13371 [03:00<00:00, 74.15it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A\n",
      "Epoch 99: 100%|█████████████████████████████████████████| 13371/13371 [03:08<00:00, 70.78it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|█████████████████████████████████████████| 13371/13371 [03:08<00:00, 70.77it/s, v_num=1278, train_loss=2.830, val_loss=2.760]\n",
      "DONE SAVING PRETRAINED MODEL\n",
      "   | Name                                         | Type                 | Params | Mode \n",
      "-----------------------------------------------------------------------------------------------\n",
      "0  | task_loss_fn                                 | MSELoss              | 0      | train\n",
      "1  | mask_loss_fn                                 | BCELoss              | 0      | train\n",
      "2  | categorical_feature_loss_fn                  | BCELoss              | 0      | train\n",
      "3  | continuous_feature_loss_fn                   | MSELoss              | 0      | train\n",
      "4  | consistency_loss_fn                          | MSELoss              | 0      | train\n",
      "5  | model                                        | VIME                 | 278 K  | train\n",
      "6  | model._VIME__encoder                         | VIMESelfSupervised   | 177 K  | train\n",
      "7  | model._VIME__encoder.encoder                 | MLP                  | 140 K  | train\n",
      "8  | model._VIME__encoder.encoder.linear_0        | Linear               | 18.6 K | train\n",
      "9  | model._VIME__encoder.encoder.batchnorm_0     | BatchNorm1d          | 400    | train\n",
      "10 | model._VIME__encoder.encoder.relu_0          | ReLU                 | 0      | train\n",
      "11 | model._VIME__encoder.encoder.dropout_0       | Dropout              | 0      | train\n",
      "12 | model._VIME__encoder.encoder.linear_1        | Linear               | 40.2 K | train\n",
      "13 | model._VIME__encoder.encoder.batchnorm_1     | BatchNorm1d          | 400    | train\n",
      "14 | model._VIME__encoder.encoder.relu_1          | ReLU                 | 0      | train\n",
      "15 | model._VIME__encoder.encoder.dropout_1       | Dropout              | 0      | train\n",
      "16 | model._VIME__encoder.encoder.linear_2        | Linear               | 40.2 K | train\n",
      "17 | model._VIME__encoder.encoder.batchnorm_2     | BatchNorm1d          | 400    | train\n",
      "18 | model._VIME__encoder.encoder.relu_2          | ReLU                 | 0      | train\n",
      "19 | model._VIME__encoder.encoder.dropout_2       | Dropout              | 0      | train\n",
      "20 | model._VIME__encoder.encoder.linear_n_layers | Linear               | 40.2 K | train\n",
      "21 | model._VIME__encoder.mask_output             | Linear               | 18.5 K | train\n",
      "22 | model._VIME__encoder.feature_output          | Linear               | 18.5 K | train\n",
      "23 | model.one_layer_prediction_head              | VIMESemiSupervised_1 | 40.4 K | train\n",
      "24 | model.one_layer_prediction_head.fc1          | Linear               | 40.2 K | train\n",
      "25 | model.one_layer_prediction_head.fc3          | Linear               | 201    | train\n",
      "26 | model.two_layer_prediction_head              | VIMESemiSupervised_2 | 60.4 K | train\n",
      "27 | model.two_layer_prediction_head.fc1          | Linear               | 40.2 K | train\n",
      "28 | model.two_layer_prediction_head.fc2          | Linear               | 20.1 K | train\n",
      "29 | model.two_layer_prediction_head.fc3          | Linear               | 101    | train\n",
      "-----------------------------------------------------------------------------------------------\n",
      "278 K     Trainable params\n",
      "0         Non-trainable params\n",
      "278 K     Total params\n",
      "1.113     Total estimated model params size (MB)\n",
      "DONE PRETRAINING\n"
     ]
    }
   ],
   "source": [
    "s3l_training(pretrain=True, # if True First Phase training\n",
    "             use_pretrained_model=False, # if True Second Phase learning\n",
    "             pt_type='vime', \n",
    "             pt_folder='FP2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7160f9-4db4-4688-9556-ba884a04eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0e795-750f-45ce-9a6a-b578608c7f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
