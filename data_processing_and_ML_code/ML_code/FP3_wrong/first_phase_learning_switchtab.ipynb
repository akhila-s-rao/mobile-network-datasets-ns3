{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed58de6-5ac0-4bbb-95e7-c77e64dfaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "#%reset\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# DEBUG MODE\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "    \n",
    "from s3l_training import s3l_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb320c-c17f-40dd-8264-6dcbd0933f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random seed:  561\n",
      "GPU is available.\n",
      "1\n",
      "True\n",
      "12.1\n",
      "Concatenating runs:  range(1, 11)\n",
      "Time to read csv file for run:  4.435908794403076\n",
      "Loaded run 1\n",
      "Time to read csv file for run:  4.224978685379028\n",
      "Loaded run 2\n",
      "Time to read csv file for run:  5.29029655456543\n",
      "Loaded run 3\n",
      "Time to read csv file for run:  5.230562925338745\n",
      "Loaded run 4\n",
      "Time to read csv file for run:  4.906632423400879\n",
      "Loaded run 5\n",
      "Time to read csv file for run:  4.5796239376068115\n",
      "Loaded run 6\n",
      "Time to read csv file for run:  4.8719213008880615\n",
      "Loaded run 7\n",
      "Time to read csv file for run:  4.949469566345215\n",
      "Loaded run 8\n",
      "Time to read csv file for run:  4.725833415985107\n",
      "Loaded run 9\n",
      "Time to read csv file for run:  4.800964832305908\n",
      "Loaded run 10\n",
      "pretrain_data, before removing rows that dont have traffic  (1799100, 102)\n",
      "pretrain_data, after removing rows that dont have traffic  (33012, 102)\n",
      "X_pretrain  (32691, 92)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refresh rate:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                   | Type      | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | task_loss_fn           | L1Loss    | 0      | train\n",
      "1 | reconstruction_loss_fn | MSELoss   | 0      | train\n",
      "2 | model                  | SwitchTab | 657 K  | train\n",
      "-------------------------------------------------------------\n",
      "657 K     Trainable params\n",
      "0         Non-trainable params\n",
      "657 K     Total params\n",
      "2.630     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████| 232/232 [00:07<00:00, 32.88it/s, v_num=542]\n",
      "Epoch 1: 100%|███████| 232/232 [00:06<00:00, 38.19it/s, v_num=542, train_loss=1.180, val_loss=0.894]\u001b[A\n",
      "Epoch 2: 100%|███████| 232/232 [00:05<00:00, 40.15it/s, v_num=542, train_loss=0.900, val_loss=0.847]\u001b[A\n",
      "Epoch 3: 100%|███████| 232/232 [00:06<00:00, 38.20it/s, v_num=542, train_loss=0.865, val_loss=0.827]\u001b[A\n",
      "Epoch 4: 100%|███████| 232/232 [00:05<00:00, 39.40it/s, v_num=542, train_loss=0.839, val_loss=0.814]\u001b[A\n",
      "Epoch 5: 100%|███████| 232/232 [00:05<00:00, 39.06it/s, v_num=542, train_loss=0.834, val_loss=0.819]\u001b[A\n",
      "Epoch 6: 100%|███████| 232/232 [00:06<00:00, 37.69it/s, v_num=542, train_loss=0.818, val_loss=0.813]\u001b[A\n",
      "Epoch 7: 100%|███████| 232/232 [00:06<00:00, 37.73it/s, v_num=542, train_loss=0.819, val_loss=0.791]\u001b[A\n",
      "Epoch 8: 100%|███████| 232/232 [00:06<00:00, 38.58it/s, v_num=542, train_loss=0.805, val_loss=0.796]\u001b[A\n",
      "Epoch 9: 100%|███████| 232/232 [00:06<00:00, 38.24it/s, v_num=542, train_loss=0.810, val_loss=0.792]\u001b[A\n",
      "Epoch 10: 100%|██████| 232/232 [00:06<00:00, 38.62it/s, v_num=542, train_loss=0.803, val_loss=0.787]\u001b[A\n",
      "Epoch 11: 100%|██████| 232/232 [00:06<00:00, 38.61it/s, v_num=542, train_loss=0.809, val_loss=0.802]\u001b[A\n",
      "Epoch 12: 100%|██████| 232/232 [00:06<00:00, 38.10it/s, v_num=542, train_loss=0.800, val_loss=0.791]\u001b[A\n",
      "Epoch 13: 100%|██████| 232/232 [00:05<00:00, 39.34it/s, v_num=542, train_loss=0.804, val_loss=0.776]\u001b[A\n",
      "Epoch 14: 100%|██████| 232/232 [00:05<00:00, 38.88it/s, v_num=542, train_loss=0.805, val_loss=0.774]\u001b[A\n",
      "Epoch 15: 100%|██████| 232/232 [00:06<00:00, 38.49it/s, v_num=542, train_loss=0.799, val_loss=0.773]\u001b[A\n",
      "Epoch 16: 100%|██████| 232/232 [00:06<00:00, 37.83it/s, v_num=542, train_loss=0.802, val_loss=0.773]\u001b[A\n",
      "Epoch 17: 100%|██████| 232/232 [00:06<00:00, 38.40it/s, v_num=542, train_loss=0.794, val_loss=0.796]\u001b[A\n",
      "Epoch 18: 100%|██████| 232/232 [00:05<00:00, 40.80it/s, v_num=542, train_loss=0.803, val_loss=0.767]\u001b[A\n",
      "Epoch 19: 100%|██████| 232/232 [00:05<00:00, 38.67it/s, v_num=542, train_loss=0.797, val_loss=0.767]\u001b[A\n",
      "Epoch 20: 100%|██████| 232/232 [00:06<00:00, 37.79it/s, v_num=542, train_loss=0.790, val_loss=0.784]\u001b[A\n",
      "Epoch 21: 100%|██████| 232/232 [00:06<00:00, 38.65it/s, v_num=542, train_loss=0.790, val_loss=0.765]\u001b[A\n",
      "Epoch 22: 100%|██████| 232/232 [00:06<00:00, 38.28it/s, v_num=542, train_loss=0.792, val_loss=0.790]\u001b[A\n",
      "Epoch 23: 100%|██████| 232/232 [00:06<00:00, 38.49it/s, v_num=542, train_loss=0.788, val_loss=0.792]\u001b[A\n",
      "Epoch 24: 100%|██████| 232/232 [00:06<00:00, 38.41it/s, v_num=542, train_loss=0.791, val_loss=0.772]\u001b[A\n",
      "Epoch 25: 100%|██████| 232/232 [00:05<00:00, 39.35it/s, v_num=542, train_loss=0.781, val_loss=0.768]\u001b[A\n",
      "Epoch 26: 100%|██████| 232/232 [00:05<00:00, 39.72it/s, v_num=542, train_loss=0.791, val_loss=0.771]\u001b[A\n",
      "Epoch 27: 100%|██████| 232/232 [00:05<00:00, 40.35it/s, v_num=542, train_loss=0.783, val_loss=0.779]\u001b[A\n",
      "Epoch 28: 100%|██████| 232/232 [00:05<00:00, 41.44it/s, v_num=542, train_loss=0.792, val_loss=0.754]\u001b[A\n",
      "Epoch 29: 100%|██████| 232/232 [00:05<00:00, 41.25it/s, v_num=542, train_loss=0.791, val_loss=0.766]\u001b[A\n",
      "Epoch 30: 100%|██████| 232/232 [00:06<00:00, 38.53it/s, v_num=542, train_loss=0.793, val_loss=0.759]\u001b[A\n",
      "Epoch 31: 100%|██████| 232/232 [00:05<00:00, 39.42it/s, v_num=542, train_loss=0.789, val_loss=0.768]\u001b[A\n",
      "Epoch 32: 100%|██████| 232/232 [00:05<00:00, 39.60it/s, v_num=542, train_loss=0.779, val_loss=0.770]\u001b[A\n",
      "Epoch 33: 100%|██████| 232/232 [00:05<00:00, 39.85it/s, v_num=542, train_loss=0.790, val_loss=0.771]\u001b[A\n",
      "Epoch 34: 100%|██████| 232/232 [00:05<00:00, 39.18it/s, v_num=542, train_loss=0.785, val_loss=0.793]\u001b[A\n",
      "Epoch 35: 100%|██████| 232/232 [00:05<00:00, 38.99it/s, v_num=542, train_loss=0.780, val_loss=0.774]\u001b[A\n",
      "Epoch 36: 100%|██████| 232/232 [00:06<00:00, 38.54it/s, v_num=542, train_loss=0.785, val_loss=0.766]\u001b[A\n",
      "Epoch 37: 100%|██████| 232/232 [00:05<00:00, 38.82it/s, v_num=542, train_loss=0.783, val_loss=0.760]\u001b[A\n",
      "Epoch 38: 100%|██████| 232/232 [00:06<00:00, 38.61it/s, v_num=542, train_loss=0.785, val_loss=0.767]\u001b[A\n",
      "Epoch 39: 100%|██████| 232/232 [00:05<00:00, 39.44it/s, v_num=542, train_loss=0.783, val_loss=0.777]\u001b[A\n",
      "Epoch 40: 100%|██████| 232/232 [00:05<00:00, 39.78it/s, v_num=542, train_loss=0.789, val_loss=0.770]\u001b[A\n",
      "Epoch 41: 100%|██████| 232/232 [00:06<00:00, 37.50it/s, v_num=542, train_loss=0.791, val_loss=0.744]\u001b[A\n",
      "Epoch 42: 100%|██████| 232/232 [00:06<00:00, 37.78it/s, v_num=542, train_loss=0.791, val_loss=0.768]\u001b[A\n",
      "Epoch 43: 100%|██████| 232/232 [00:06<00:00, 37.51it/s, v_num=542, train_loss=0.790, val_loss=0.771]\u001b[A\n",
      "Epoch 44: 100%|██████| 232/232 [00:06<00:00, 38.18it/s, v_num=542, train_loss=0.796, val_loss=0.757]\u001b[A\n",
      "Epoch 45: 100%|██████| 232/232 [00:06<00:00, 37.27it/s, v_num=542, train_loss=0.783, val_loss=0.737]\u001b[A\n",
      "Epoch 46: 100%|██████| 232/232 [00:06<00:00, 37.73it/s, v_num=542, train_loss=0.792, val_loss=0.769]\u001b[A\n",
      "Epoch 47: 100%|██████| 232/232 [00:06<00:00, 37.87it/s, v_num=542, train_loss=0.786, val_loss=0.762]\u001b[A\n",
      "Epoch 48: 100%|██████| 232/232 [00:06<00:00, 37.95it/s, v_num=542, train_loss=0.785, val_loss=0.770]\u001b[A\n",
      "Epoch 49: 100%|██████| 232/232 [00:06<00:00, 37.56it/s, v_num=542, train_loss=0.790, val_loss=0.769]\u001b[A\n",
      "Epoch 50: 100%|██████| 232/232 [00:06<00:00, 37.51it/s, v_num=542, train_loss=0.777, val_loss=0.764]\u001b[A\n",
      "Epoch 51: 100%|██████| 232/232 [00:06<00:00, 37.47it/s, v_num=542, train_loss=0.786, val_loss=0.780]\u001b[A\n",
      "Epoch 52: 100%|██████| 232/232 [00:06<00:00, 37.79it/s, v_num=542, train_loss=0.780, val_loss=0.771]\u001b[A\n",
      "Epoch 53: 100%|██████| 232/232 [00:06<00:00, 37.61it/s, v_num=542, train_loss=0.785, val_loss=0.767]\u001b[A\n",
      "Epoch 54: 100%|██████| 232/232 [00:06<00:00, 37.36it/s, v_num=542, train_loss=0.779, val_loss=0.803]\u001b[A\n",
      "Epoch 55: 100%|██████| 232/232 [00:06<00:00, 36.95it/s, v_num=542, train_loss=0.799, val_loss=0.793]\u001b[A\n",
      "Epoch 56: 100%|██████| 232/232 [00:06<00:00, 35.42it/s, v_num=542, train_loss=0.782, val_loss=0.774]\u001b[A\n",
      "Epoch 57: 100%|██████| 232/232 [00:06<00:00, 38.34it/s, v_num=542, train_loss=0.777, val_loss=0.776]\u001b[A\n",
      "Epoch 58: 100%|██████| 232/232 [00:06<00:00, 38.25it/s, v_num=542, train_loss=0.779, val_loss=0.768]\u001b[A\n",
      "Epoch 59: 100%|██████| 232/232 [00:06<00:00, 38.45it/s, v_num=542, train_loss=0.783, val_loss=0.770]\u001b[A\n",
      "Epoch 60: 100%|██████| 232/232 [00:05<00:00, 38.71it/s, v_num=542, train_loss=0.789, val_loss=0.767]\u001b[A\n",
      "Epoch 61: 100%|██████| 232/232 [00:06<00:00, 38.41it/s, v_num=542, train_loss=0.782, val_loss=0.751]\u001b[A\n",
      "Epoch 62: 100%|██████| 232/232 [00:05<00:00, 38.72it/s, v_num=542, train_loss=0.786, val_loss=0.749]\u001b[A\n",
      "Epoch 63: 100%|██████| 232/232 [00:06<00:00, 38.54it/s, v_num=542, train_loss=0.774, val_loss=0.755]\u001b[A\n",
      "Epoch 64: 100%|██████| 232/232 [00:05<00:00, 38.99it/s, v_num=542, train_loss=0.779, val_loss=0.743]\u001b[A\n",
      "Epoch 65: 100%|██████| 232/232 [00:06<00:00, 38.56it/s, v_num=542, train_loss=0.782, val_loss=0.752]\u001b[A\n",
      "Epoch 66: 100%|██████| 232/232 [00:06<00:00, 38.51it/s, v_num=542, train_loss=0.788, val_loss=0.771]\u001b[A\n",
      "Epoch 67: 100%|██████| 232/232 [00:06<00:00, 38.15it/s, v_num=542, train_loss=0.783, val_loss=0.757]\u001b[A\n",
      "Epoch 68: 100%|██████| 232/232 [00:06<00:00, 38.61it/s, v_num=542, train_loss=0.771, val_loss=0.761]\u001b[A\n",
      "Epoch 69: 100%|██████| 232/232 [00:06<00:00, 38.46it/s, v_num=542, train_loss=0.781, val_loss=0.773]\u001b[A\n",
      "Epoch 70: 100%|██████| 232/232 [00:06<00:00, 38.55it/s, v_num=542, train_loss=0.785, val_loss=0.755]\u001b[A\n",
      "Epoch 71: 100%|██████| 232/232 [00:05<00:00, 38.69it/s, v_num=542, train_loss=0.783, val_loss=0.759]\u001b[A\n",
      "Epoch 72: 100%|██████| 232/232 [00:06<00:00, 38.46it/s, v_num=542, train_loss=0.782, val_loss=0.772]\u001b[A\n",
      "Epoch 73: 100%|██████| 232/232 [00:06<00:00, 37.97it/s, v_num=542, train_loss=0.782, val_loss=0.784]\u001b[A\n",
      "Epoch 74: 100%|██████| 232/232 [00:06<00:00, 37.49it/s, v_num=542, train_loss=0.781, val_loss=0.754]\u001b[A\n",
      "Epoch 75: 100%|██████| 232/232 [00:06<00:00, 37.28it/s, v_num=542, train_loss=0.787, val_loss=0.764]\u001b[A\n",
      "Epoch 76: 100%|██████| 232/232 [00:06<00:00, 37.32it/s, v_num=542, train_loss=0.778, val_loss=0.772]\u001b[A\n",
      "Epoch 77: 100%|██████| 232/232 [00:06<00:00, 38.18it/s, v_num=542, train_loss=0.776, val_loss=0.756]\u001b[A\n",
      "Epoch 78: 100%|██████| 232/232 [00:06<00:00, 38.45it/s, v_num=542, train_loss=0.784, val_loss=0.760]\u001b[A\n",
      "Epoch 79: 100%|██████| 232/232 [00:06<00:00, 38.07it/s, v_num=542, train_loss=0.781, val_loss=0.752]\u001b[A\n",
      "Epoch 80: 100%|██████| 232/232 [00:06<00:00, 38.38it/s, v_num=542, train_loss=0.771, val_loss=0.781]\u001b[A\n",
      "Epoch 81: 100%|██████| 232/232 [00:06<00:00, 38.20it/s, v_num=542, train_loss=0.783, val_loss=0.792]\u001b[A\n",
      "Epoch 82: 100%|██████| 232/232 [00:06<00:00, 38.44it/s, v_num=542, train_loss=0.776, val_loss=0.762]\u001b[A\n",
      "Epoch 83: 100%|██████| 232/232 [00:06<00:00, 38.21it/s, v_num=542, train_loss=0.780, val_loss=0.757]\u001b[A\n",
      "Epoch 84: 100%|██████| 232/232 [00:06<00:00, 38.18it/s, v_num=542, train_loss=0.786, val_loss=0.774]\u001b[A\n",
      "Epoch 85: 100%|██████| 232/232 [00:06<00:00, 38.20it/s, v_num=542, train_loss=0.784, val_loss=0.755]\u001b[A\n",
      "Epoch 86: 100%|██████| 232/232 [00:06<00:00, 38.41it/s, v_num=542, train_loss=0.773, val_loss=0.777]\u001b[A\n",
      "Epoch 87: 100%|██████| 232/232 [00:06<00:00, 38.62it/s, v_num=542, train_loss=0.781, val_loss=0.751]\u001b[A\n",
      "Epoch 88: 100%|██████| 232/232 [00:05<00:00, 39.46it/s, v_num=542, train_loss=0.783, val_loss=0.754]\u001b[A\n",
      "Epoch 89: 100%|██████| 232/232 [00:06<00:00, 37.54it/s, v_num=542, train_loss=0.774, val_loss=0.783]\u001b[A\n",
      "Epoch 90: 100%|██████| 232/232 [00:06<00:00, 38.34it/s, v_num=542, train_loss=0.775, val_loss=0.783]\u001b[A\n",
      "Epoch 91: 100%|██████| 232/232 [00:06<00:00, 38.20it/s, v_num=542, train_loss=0.778, val_loss=0.795]\u001b[A\n",
      "Epoch 92: 100%|██████| 232/232 [00:06<00:00, 38.10it/s, v_num=542, train_loss=0.787, val_loss=0.770]\u001b[A\n",
      "Epoch 93: 100%|██████| 232/232 [00:06<00:00, 37.86it/s, v_num=542, train_loss=0.785, val_loss=0.745]\u001b[A\n",
      "Epoch 94: 100%|██████| 232/232 [00:05<00:00, 38.67it/s, v_num=542, train_loss=0.775, val_loss=0.760]\u001b[A\n",
      "Epoch 95: 100%|██████| 232/232 [00:06<00:00, 38.37it/s, v_num=542, train_loss=0.782, val_loss=0.749]\u001b[A\n",
      "Epoch 96: 100%|██████| 232/232 [00:06<00:00, 38.59it/s, v_num=542, train_loss=0.783, val_loss=0.771]\u001b[A\n",
      "Epoch 97: 100%|██████| 232/232 [00:05<00:00, 39.08it/s, v_num=542, train_loss=0.776, val_loss=0.759]\u001b[A\n",
      "Epoch 98: 100%|██████| 232/232 [00:06<00:00, 38.64it/s, v_num=542, train_loss=0.777, val_loss=0.765]\u001b[A\n",
      "Epoch 99: 100%|██████| 232/232 [00:05<00:00, 38.76it/s, v_num=542, train_loss=0.783, val_loss=0.772]\u001b[A\n",
      "Epoch 99: 100%|██████| 232/232 [00:06<00:00, 35.09it/s, v_num=542, train_loss=0.783, val_loss=0.760]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████| 232/232 [00:06<00:00, 34.91it/s, v_num=542, train_loss=0.783, val_loss=0.760]"
     ]
    }
   ],
   "source": [
    "s3l_training(pretrain=True, # if True First Phase training\n",
    "             use_pretrained_model=False, # if True Second Phase learning\n",
    "             pt_type='switchtab', \n",
    "             pt_folder='FP3_only_traffic_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7160f9-4db4-4688-9556-ba884a04eafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
